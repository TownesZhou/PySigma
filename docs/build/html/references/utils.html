

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Utils &mdash; PySigma  documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Example Models" href="../examples/index.html" />
    <link rel="prev" title="Other Structural Nodes" href="graphical/other-structural-nodes.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> PySigma
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Table of Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../introduction/intro.html">Introduction and Tutorials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../introduction/getting-started.html">Getting Started</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">API References</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="cognitive.html">Cognitive Language Interface</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cognitive.html#type">Type</a></li>
<li class="toctree-l3"><a class="reference internal" href="cognitive.html#predicate">Predicate</a></li>
<li class="toctree-l3"><a class="reference internal" href="cognitive.html#conditional">Conditional</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="graphical/index.html">Graphical Architecture</a><ul>
<li class="toctree-l3"><a class="reference internal" href="graphical/data-structures.html">Basic Data Structures</a><ul>
<li class="toctree-l4"><a class="reference internal" href="graphical/data-structures.html#variable-metatypes">Variable Metatypes</a></li>
<li class="toctree-l4"><a class="reference internal" href="graphical/data-structures.html#variable">Variable</a></li>
<li class="toctree-l4"><a class="reference internal" href="graphical/data-structures.html#message-types">Message Types</a></li>
<li class="toctree-l4"><a class="reference internal" href="graphical/data-structures.html#message">Message</a></li>
<li class="toctree-l4"><a class="reference internal" href="graphical/data-structures.html#linkdata">LinkData</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="graphical/abstract-base-nodes.html">Abstract Base Nodes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="graphical/abstract-base-nodes.html#node">Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="graphical/abstract-base-nodes.html#factor-node">Factor Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="graphical/abstract-base-nodes.html#variable-node">Variable Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="graphical/abstract-base-nodes.html#alpha-factor-node">Alpha Factor Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="graphical/abstract-base-nodes.html#beta-factor-node">Beta Factor Node</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="graphical/predicate-nodes.html">Predicate Subgraph Nodes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="graphical/predicate-nodes.html#working-memory-variable-node">Working Memory Variable Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="graphical/predicate-nodes.html#long-term-memory-factor-node">Long-Term Memory Factor Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="graphical/predicate-nodes.html#perceptual-buffer-node">Perceptual Buffer Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="graphical/predicate-nodes.html#working-memory-factor-node">Working Memory Factor Node</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="graphical/conditional-nodes.html">Conditional Subgraph Nodes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="graphical/conditional-nodes.html#relational-mapping-factor-node">Relational Mapping Factor Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="graphical/conditional-nodes.html#expansion-summarization-factor-node">Expansion / Summarization Factor Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="graphical/conditional-nodes.html#concatenation-marginalization-transformation-factor-node">Concatenation, Marginalization, &amp; Transformation Factor Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="graphical/conditional-nodes.html#event-resolution-factor-node">Event Resolution Factor Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="graphical/conditional-nodes.html#beta-join-factor-node">Beta Join Factor Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="graphical/conditional-nodes.html#gamma-factor-node">Gamma Factor Node</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="graphical/other-structural-nodes.html">Other Structural Nodes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="graphical/other-structural-nodes.html#default-factor-node">Default Factor Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="graphical/other-structural-nodes.html#default-variable-node">Default Variable Node</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Utils</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#distributionserver">DistributionServer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#knowledgeserver">KnowledgeServer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html">Example Models</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">PySigma</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">API References</a> &raquo;</li>
        
      <li>Utils</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/references/utils.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="utils">
<h1>Utils<a class="headerlink" href="#utils" title="Permalink to this headline">¶</a></h1>
<div class="section" id="distributionserver">
<h2>DistributionServer<a class="headerlink" href="#distributionserver" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="pysigma.utils.DistributionServer">
<em class="property">class </em><code class="sig-prename descclassname">pysigma.utils.</code><code class="sig-name descname">DistributionServer</code><a class="reference internal" href="../_modules/pysigma/utils.html#DistributionServer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysigma.utils.DistributionServer" title="Permalink to this definition">¶</a></dt>
<dd><p>Serving distribution class dependent utilities</p>
<ul>
<li><p>Conversion between PyTorch distribution parameters and distribution instance:</p>
<p><code class="docutils literal notranslate"><span class="pre">param2dist()</span></code>, <code class="docutils literal notranslate"><span class="pre">dist2param()</span></code></p>
</li>
<li><p>Translation between PyTorch distribution parameters and natural parameters for exponential family distribution:</p>
<p><code class="docutils literal notranslate"><span class="pre">natural2exp_dist()</span></code>, <code class="docutils literal notranslate"><span class="pre">exp_dist2natural()</span></code></p>
</li>
<li><p>Get vector of moments from a given distribution instance:</p>
<p><code class="docutils literal notranslate"><span class="pre">get_moments()</span></code></p>
</li>
<li><p>Draw particles from distribution instance:</p>
<p><code class="docutils literal notranslate"><span class="pre">draw_particles()</span></code></p>
</li>
<li><p>Get log probability density from given particles:</p>
<p><code class="docutils literal notranslate"><span class="pre">log_pdf()</span></code></p>
</li>
</ul>
<p>Certain distribution classes require special handling, for example for those categorized as finite discrete,
particle values will be drawn uniformly, covering every value in the RV’s value range (support) once and only once,
while assigning each particle its probability mass as its particle weight.</p>
<p>Therefore we delegate all such special handling to this class on an individual basis.</p>
<p>Note that input and output will conform to the format understandable by PyTorch’s distribution class. To
translate to and from formats compatible to PySigma’s predicate knowledge, use KnowledgeServer class</p>
<dl class="py method">
<dt id="pysigma.utils.DistributionServer.param2dist">
<em class="property">classmethod </em><code class="sig-name descname">param2dist</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dist_class</span></em>, <em class="sig-param"><span class="n">param</span></em>, <em class="sig-param"><span class="n">b_shape</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">e_shape</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">dist_info</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pysigma/utils.html#DistributionServer.param2dist"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysigma.utils.DistributionServer.param2dist" title="Permalink to this definition">¶</a></dt>
<dd><p>Converts distribution parameter to a distribution instance.</p>
<p>Depending on the context and Predicate knowledge format, the parameter <cite>param</cite> may belong to different
representation systems, in which case it should be interpreted differently. Such specification should be
sufficiently described in the argument <cite>dist_info</cite> in a prior consent format.</p>
<p>The optional arguments <cite>b_shape</cite> and <cite>e_shape</cite> stand for distribution’s batch shape and event shape
respectively. They are used primarily for sanity check. Note that this event shape <cite>e_shape</cite> pertains to
PyTorch’s distribution class specification, and therefore may or may not be different from the event shape of
particles in PySigma’s cognitive format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dist_class</strong> (<em>type</em>) – The distribution class. Must be a subclass of <code class="docutils literal notranslate"><span class="pre">torch.distributions.Distribution</span></code>.</p></li>
<li><p><strong>param</strong> (<em>torch.Tensor</em>) – The parameter tensor. The last dimension is assumed to be the parameter dimension, and sizes of the
dimensions at the front should be equal to <cite>b_shape</cite>.</p></li>
<li><p><strong>b_shape</strong> (<em>torch.Size</em><em>, </em><em>optional</em>) – The batch shape of the distribution. Used for shape sanity check.</p></li>
<li><p><strong>e_shape</strong> (<em>torch.Size</em><em>, </em><em>optional</em>) – The presumed event shape of the distribution. Used for shape sanity check.</p></li>
<li><p><strong>dist_info</strong> (<em>dict</em><em>, </em><em>optional</em>) – An optional dict containing all relevant information in order to correctly interpret the parameter <cite>param</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The instantiated distribution instance.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.distributions.Distribution</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>NotImplementedError</strong> – If the conversion procedure specific to <cite>dist_class</cite> has not been implemented yet.</p></li>
<li><p><strong>ValueError</strong> – If the converted distribution instance has different batch shape and event shape than specified <cite>b_shape</cite>
    and <cite>e_shape</cite> respectively.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pysigma.utils.DistributionServer.dist2param">
<em class="property">classmethod </em><code class="sig-name descname">dist2param</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dist</span></em>, <em class="sig-param"><span class="n">dist_info</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pysigma/utils.html#DistributionServer.dist2param"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysigma.utils.DistributionServer.dist2param" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract the parameter tensor from a given distribution instance.</p>
<p>Depending on the context and Predicate knowledge format, the desired parameter may belong to different
representation systems, in which case it should be generated differently. Such specification should be
sufficiently described in the argument <cite>dist_info</cite> in a prior consent format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dist</strong> (<em>torch.distributions.Distribution</em>) – The distribution instance from which to extract the parameter.</p></li>
<li><p><strong>dist_info</strong> (<em>dict</em><em>, </em><em>optional</em>) – An optional dict containing all relevant information in order to correctly generate the parameter <cite>param</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The parameter tensor in the desired format.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>NotImplementedError</strong> – If the conversion procedure specific to the distribution class of <cite>dist</cite> has not been implemented yet.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pysigma.utils.DistributionServer.get_moments">
<em class="property">classmethod </em><code class="sig-name descname">get_moments</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dist</span></em>, <em class="sig-param"><span class="n">n_moments</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pysigma/utils.html#DistributionServer.get_moments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysigma.utils.DistributionServer.get_moments" title="Permalink to this definition">¶</a></dt>
<dd><p>Get vector of moments from a given distribution instance</p>
<div class="admonition-todo admonition" id="id1">
<p class="admonition-title">Todo</p>
<p>Implement with dist_info</p>
</div>
</dd></dl>

<dl class="py method">
<dt id="pysigma.utils.DistributionServer.draw_particles">
<em class="property">classmethod </em><code class="sig-name descname">draw_particles</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dist</span></em>, <em class="sig-param"><span class="n">num_particles</span></em>, <em class="sig-param"><span class="n">b_shape</span></em>, <em class="sig-param"><span class="n">e_shape</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pysigma/utils.html#DistributionServer.draw_particles"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysigma.utils.DistributionServer.draw_particles" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition-todo admonition" id="id2">
<p class="admonition-title">Todo</p>
<p>Gibbs sampling procedure</p>
</div>
<dl class="simple">
<dt>Draw a given number of particles from the given batch of distribution instances. Return a tuple:</dt><dd><p>(particles, weights, sampling_log_densities)</p>
</dd>
<dt>The Gibbs’ Sampling procedure is used to draw a single list of particles that will be used by each</dt><dd><p>distribution instance in the batch to derive individual weights by importance weighting.</p>
</dd>
</dl>
<p>Particles drawn are in the format compatible with PyTorch’s distribution class</p>
</dd></dl>

<dl class="py method">
<dt id="pysigma.utils.DistributionServer.log_prob">
<em class="property">classmethod </em><code class="sig-name descname">log_prob</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dist</span></em>, <em class="sig-param"><span class="n">values</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pysigma/utils.html#DistributionServer.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysigma.utils.DistributionServer.log_prob" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the log probability mass/density of the given particle values w.r.t. the given batched distribution
instance.</p>
<p>The particle value should be in PyTorch format that is compatible with PyTorch’s distribution classes. This
means the last dimension of <cite>values</cite> is assumed the event dimension, and should be compatible with, if not
identical to, <code class="docutils literal notranslate"><span class="pre">dist.event_shape</span></code>. Every other dimensions to the front is assumed sample dimensions, the sizes
of which together forms the <code class="docutils literal notranslate"><span class="pre">sample_shape</span></code>.</p>
<p>The distribution instance <cite>dist</cite> is assumed batched. In other words, its batch shape <code class="docutils literal notranslate"><span class="pre">dist.batch_shape</span></code> should
not be empty.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dist</strong> (<em>torch.distributions.Distribution</em>) – A batched distribution instance. Its batch shape <code class="docutils literal notranslate"><span class="pre">dist.batch_shape</span></code> should not be empty.</p></li>
<li><p><strong>values</strong> (<em>torch.Tensor</em>) – A 2D tensor with shape <code class="docutils literal notranslate"><span class="pre">(sample_shape</span> <span class="pre">+</span> <span class="pre">[event_size])</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The log probability mass/density tensor, of shape <code class="docutils literal notranslate"><span class="pre">(dist.batch_shape</span> <span class="pre">+</span> <span class="pre">sample_shape)</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AssertionError</strong> – If the <code class="docutils literal notranslate"><span class="pre">event_size</span></code> found in <cite>values</cite> is different from <cite>dist.event_shape</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pysigma.utils.DistributionServer.kl_norm">
<em class="property">classmethod </em><code class="sig-name descname">kl_norm</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dist1</span></em>, <em class="sig-param"><span class="n">dist2</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pysigma/utils.html#DistributionServer.kl_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysigma.utils.DistributionServer.kl_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the norm of the KL divergence of two given batched distributions</p>
</dd></dl>

<dl class="py method">
<dt id="pysigma.utils.DistributionServer.transform_param">
<em class="property">classmethod </em><code class="sig-name descname">transform_param</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">param</span></em>, <em class="sig-param"><span class="n">dist_info</span></em>, <em class="sig-param"><span class="n">trans</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pysigma/utils.html#DistributionServer.transform_param"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysigma.utils.DistributionServer.transform_param" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition-todo admonition" id="id3">
<p class="admonition-title">Todo</p>
<p>To implement</p>
</div>
<p>Return the parameter of the transformed distribution</p>
</dd></dl>

<dl class="py attribute">
<dt id="pysigma.utils.DistributionServer.dict_draw_particles">
<code class="sig-name descname">dict_draw_particles</code><em class="property"> = {&lt;class 'torch.distributions.categorical.Categorical'&gt;: &lt;classmethod object&gt;}</em><a class="headerlink" href="#pysigma.utils.DistributionServer.dict_draw_particles" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="pysigma.utils.DistributionServer.dict_log_pdf">
<code class="sig-name descname">dict_log_pdf</code><em class="property"> = {}</em><a class="headerlink" href="#pysigma.utils.DistributionServer.dict_log_pdf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="pysigma.utils.DistributionServer.dict_param2dist">
<code class="sig-name descname">dict_param2dist</code><em class="property"> = {}</em><a class="headerlink" href="#pysigma.utils.DistributionServer.dict_param2dist" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="pysigma.utils.DistributionServer.dict_dist2param">
<code class="sig-name descname">dict_dist2param</code><em class="property"> = {}</em><a class="headerlink" href="#pysigma.utils.DistributionServer.dict_dist2param" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="pysigma.utils.DistributionServer.dict_natural2exp_param">
<code class="sig-name descname">dict_natural2exp_param</code><em class="property"> = {}</em><a class="headerlink" href="#pysigma.utils.DistributionServer.dict_natural2exp_param" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="pysigma.utils.DistributionServer.dict_exp_param2natural">
<code class="sig-name descname">dict_exp_param2natural</code><em class="property"> = {}</em><a class="headerlink" href="#pysigma.utils.DistributionServer.dict_exp_param2natural" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="pysigma.utils.DistributionServer.dict_natural2exp_dist">
<code class="sig-name descname">dict_natural2exp_dist</code><em class="property"> = {}</em><a class="headerlink" href="#pysigma.utils.DistributionServer.dict_natural2exp_dist" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="pysigma.utils.DistributionServer.dict_exp_dist2natural">
<code class="sig-name descname">dict_exp_dist2natural</code><em class="property"> = {}</em><a class="headerlink" href="#pysigma.utils.DistributionServer.dict_exp_dist2natural" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="pysigma.utils.DistributionServer.dict_get_moments">
<code class="sig-name descname">dict_get_moments</code><em class="property"> = {}</em><a class="headerlink" href="#pysigma.utils.DistributionServer.dict_get_moments" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="knowledgeserver">
<h2>KnowledgeServer<a class="headerlink" href="#knowledgeserver" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="pysigma.utils.KnowledgeServer">
<em class="property">class </em><code class="sig-prename descclassname">pysigma.utils.</code><code class="sig-name descname">KnowledgeServer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dist_class</span></em>, <em class="sig-param"><span class="n">rv_sizes</span></em>, <em class="sig-param"><span class="n">rv_constraints</span></em>, <em class="sig-param"><span class="n">rv_num_particles</span></em>, <em class="sig-param"><span class="n">dist_info</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pysigma/utils.html#KnowledgeServer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysigma.utils.KnowledgeServer" title="Permalink to this definition">¶</a></dt>
<dd><p>Knowledge Server class. Provides service regarding a Predicate’s knowledge.</p>
<p>The architecture should hold one KnowledgeServer instance for each Predicate instantiated to cache knowledge
contents and provide distribution related service.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dist_class</strong> (<em>type</em>) – The distribution class of the Predicate’s knowledge. Must be a subclass of <code class="docutils literal notranslate"><span class="pre">torch.distributions.Distribution</span></code>.</p></li>
<li><p><strong>rv_sizes</strong> (<em>iterable of int</em>) – The sizes of the random variables of the Predicate’s knowledge. Note that the order given by the iterable will
be respected.</p></li>
<li><p><strong>rv_constraints</strong> (<em>iterable of torch.distributions.constraints.Constraint</em>) – The value constraints of the random variables. Note that the order given by the iterable will be respected.</p></li>
<li><p><strong>rv_num_particles</strong> (<em>iterable of int</em>) – The number of marginal particles that should be drawn w.r.t. each random variable. Must have the same length as
<cite>rv_sizes</cite> and <cite>rv_constraints</cite>, i.e., the number of random variables.</p></li>
<li><p><strong>dist_info</strong> (<em>dict</em><em>, </em><em>optional</em>) – An optional attribute dict that contains all necessary information for DistributionServer to draw particles and
query particles’ log pdf.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="pysigma.utils.KnowledgeServer.dist_class">
<code class="sig-name descname">dist_class</code><a class="headerlink" href="#pysigma.utils.KnowledgeServer.dist_class" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>type</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="pysigma.utils.KnowledgeServer.rv_sizes">
<code class="sig-name descname">rv_sizes</code><a class="headerlink" href="#pysigma.utils.KnowledgeServer.rv_sizes" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>tuple of int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="pysigma.utils.KnowledgeServer.rv_constraints">
<code class="sig-name descname">rv_constraints</code><a class="headerlink" href="#pysigma.utils.KnowledgeServer.rv_constraints" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>tuple of torch.distributions.constraints.Constraint</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="pysigma.utils.KnowledgeServer.rv_num_particles">
<code class="sig-name descname">rv_num_particles</code><a class="headerlink" href="#pysigma.utils.KnowledgeServer.rv_num_particles" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>tuple of int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="pysigma.utils.KnowledgeServer.dist_info">
<code class="sig-name descname">dist_info</code><a class="headerlink" href="#pysigma.utils.KnowledgeServer.dist_info" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="pysigma.utils.KnowledgeServer.num_rvs">
<code class="sig-name descname">num_rvs</code><a class="headerlink" href="#pysigma.utils.KnowledgeServer.num_rvs" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of random variables involved in specifying the Predicate knowledge.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="pysigma.utils.KnowledgeServer.e_shape">
<code class="sig-name descname">e_shape</code><a class="headerlink" href="#pysigma.utils.KnowledgeServer.e_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>The event shape of predicate’s knowledge. Inferred form <cite>rv_sizes</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>torch.Size</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="pysigma.utils.KnowledgeServer.particles">
<code class="sig-name descname">particles</code><a class="headerlink" href="#pysigma.utils.KnowledgeServer.particles" title="Permalink to this definition">¶</a></dt>
<dd><p>The cached tuple of marginal particle event tensors corresponding to the random variables. This attribute is set
when <cite>draw_grid_particles</cite> is called with <code class="docutils literal notranslate"><span class="pre">update_cache=True</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>tuple of torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="pysigma.utils.KnowledgeServer.log_densities">
<code class="sig-name descname">log_densities</code><a class="headerlink" href="#pysigma.utils.KnowledgeServer.log_densities" title="Permalink to this definition">¶</a></dt>
<dd><p>The cached tuple of log sampling density tensors corresponding to each of the marginal particle event. This
attribute is set when <cite>draw_grid_particles</cite> is called with <code class="docutils literal notranslate"><span class="pre">update_cache=True</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>tuple of torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<p>In order to provide service to both predicate nodes and conditional nodes in all stages, KnowledgeServer should
store and manipulate data regarding the random variables only. In other words, only message components that do not
involve batch dimensions should be cached; this includes particle value tensors and log sampling density tensors,
but excludes both parameter and weight tensors. The latter ones’ shapes are not invariant throughout the stages
in the conditional subgraph, and therefore should be specified by the callee.</p>
<p>Signatures for special private distribution class dependent methods:</p>
<ul class="simple">
<li><p>Cognitive to PyTorch event format translation method: <code class="docutils literal notranslate"><span class="pre">2torch_event(particles)</span> <span class="pre">--&gt;</span> <span class="pre">particles</span></code></p></li>
<li><p>PyTorch to Cognitive event format translation method: <code class="docutils literal notranslate"><span class="pre">2cognitive_event(particles)</span> <span class="pre">--&gt;</span> <span class="pre">particles</span></code></p></li>
<li><p>Special marginal particle list sampling method: <code class="docutils literal notranslate"><span class="pre">special_draw(batched_dist)</span> <span class="pre">--&gt;</span> <span class="pre">particles,</span> <span class="pre">log_densities</span></code></p></li>
</ul>
<dl class="py method">
<dt id="pysigma.utils.KnowledgeServer.draw_particles">
<code class="sig-name descname">draw_particles</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">batched_param</span></em>, <em class="sig-param"><span class="n">batch_shape</span></em>, <em class="sig-param"><span class="n">update_cache</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pysigma/utils.html#KnowledgeServer.draw_particles"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysigma.utils.KnowledgeServer.draw_particles" title="Permalink to this definition">¶</a></dt>
<dd><p>Draws new particles for the associated predicate w.r.t. the given <cite>batched_param</cite>. Returns necessary
components to instantiate a particles message.</p>
<p>This method is typically called by the predicate’s LTMFN node during modification phase, in which the new
updated batched parameter tensor has been obtained and provided by <cite>batched_param</cite>. This method is then
proceed to:</p>
<ol class="arabic simple">
<li><p>instantiate the batched distribution instances from the batched parameter tensor,</p></li>
<li><p>draw a single unique list of <strong>marginal</strong> particle values w.r.t. each random variable from the entire batch
of distribution instances,</p></li>
<li><p>calculate their corresponding marginal sampling densities,</p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batched_param</strong> (<em>torch.Tensor</em>) – The new batched parameter tensor, of shape <code class="docutils literal notranslate"><span class="pre">(batch_shape</span> <span class="pre">+</span> <span class="pre">[param_size])</span></code>.</p></li>
<li><p><strong>batch_shape</strong> (<em>torch.Size</em>) – The batch shape</p></li>
<li><p><strong>update_cache</strong> (<em>bool</em>) – Whether to replace the cache content in <code class="docutils literal notranslate"><span class="pre">self.particles</span></code> and <code class="docutils literal notranslate"><span class="pre">self.log_densities</span></code> with the result of
calling this method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>particles</strong> (<em>tuple of torch.Tensor</em>) – The marginal particle lists w.r.t. each random variable in order.</p></li>
<li><p><strong>log_densities</strong> (<em>tuple of torch.Tensor</em>) – The marginal sampling log densities w.r.t. each random variable in order.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Some remarks regarding the aforementioned step 2 and 3:</p>
<p>The tuple set of the types of the rv constraints specified in <code class="docutils literal notranslate"><span class="pre">self.rv_constraints</span></code> will be used to look up
the pre-specified method map <code class="docutils literal notranslate"><span class="pre">self.dict_2special_draw</span></code>. If an entry present, will used that method to obtain
the returning <code class="docutils literal notranslate"><span class="pre">particles</span></code> and <code class="docutils literal notranslate"><span class="pre">log_densities</span></code>. This is particularly useful, for instance, in the case of
finite discrete random variables where a regular lattice should be drawn uniformly.</p>
<p>Otherwise, the standard procedure will be carried out.
``</p>
</dd></dl>

<dl class="py method">
<dt id="pysigma.utils.KnowledgeServer.surrogate_log_prob">
<code class="sig-name descname">surrogate_log_prob</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">param</span></em>, <em class="sig-param"><span class="n">alt_particles</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pysigma/utils.html#KnowledgeServer.surrogate_log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysigma.utils.KnowledgeServer.surrogate_log_prob" title="Permalink to this definition">¶</a></dt>
<dd><p>Query the log pdf of the surrogate particles specified by <cite>alt_particles</cite> w.r.t. the cached distribution
instance.</p>
<p>Each particle tensor in <cite>alt_particles</cite> must correspond to a Predicate’s random variable in the given
order. Alternatively, <code class="docutils literal notranslate"><span class="pre">None</span></code> can be specified as an entry in <cite>alt_particles</cite> so that the cached particle
tensor of the corresponding RV remembered by this KnowledgeServer instance will be used instead.</p>
<p>By default, the cached distribution <code class="docutils literal notranslate"><span class="pre">self.cached_dist</span></code> will be queried. Alternatively, the <cite>alt_param</cite> and
<cite>alg_dist_info</cite> arguments can be specified so that a surrogate distribution instance will be instantiated and
queried.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>param</strong> (<em>torch.Tensor</em><em>, </em><em>optional</em>) – The alternative parameter from which a surrogate distribution instance is to be instantiated and log prob
being queried. Should have the same shape as the cached <code class="docutils literal notranslate"><span class="pre">self.batched_param</span></code>.</p></li>
<li><p><strong>alt_particles</strong> (<em>list of</em><em> (</em><em>torch.Tensor</em><em> or </em><em>None</em><em>)</em><em>, or </em><em>None</em>) – The surrogate particles to be queried. If not None, each entry must either be None, so that the
corresponding cached articles will be used instead, or a torch.Tensor, with a shape of length 2 and the last
dimension size equal to the corresponding value in <code class="docutils literal notranslate"><span class="pre">self.rv_sizes</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The log probability tensor, of shape <code class="docutils literal notranslate"><span class="pre">(batch_shape</span> <span class="pre">+</span> <span class="pre">sample_shape)</span></code>, where <code class="docutils literal notranslate"><span class="pre">batch_shape</span></code> is the batch
shape of the Predicate’s knowledge, and <code class="docutils literal notranslate"><span class="pre">sample_shape</span></code> is the list of sample sizes of the queried
particles in order (either those provided by <cite>alt_particles</cite> or those in <code class="docutils literal notranslate"><span class="pre">self.particles</span></code>).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>AssertionError</strong> – If <cite>self.batched_param</cite> is <code class="docutils literal notranslate"><span class="pre">None</span></code>, meaning no cached parameters to instantiate distribution instance.</p></li>
<li><p><strong>AssertionError</strong> – If <cite>alt_particles</cite> contains <code class="docutils literal notranslate"><span class="pre">None</span></code> but <code class="docutils literal notranslate"><span class="pre">self.particles</span></code> is also None, meaning no cached particles.</p></li>
<li><p><strong>AssertionError</strong> – If <cite>alt_param</cite> is specified but it has different shape than <code class="docutils literal notranslate"><span class="pre">self.batched_param</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pysigma.utils.KnowledgeServer.event2torch_event">
<code class="sig-name descname">event2torch_event</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cat_particles</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pysigma/utils.html#KnowledgeServer.event2torch_event"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysigma.utils.KnowledgeServer.event2torch_event" title="Permalink to this definition">¶</a></dt>
<dd><p>Translates joint particle event values from the Cognitive format to a format understandable by PyTorch
distribution class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>cat_particles</strong> (<em>torch.Tensor</em>) – A 2D tensor representing the list of concatenated particle events in Cognitive format. Its 2nd dimension
size should be equal to the sum of rv sizes in <code class="docutils literal notranslate"><span class="pre">self.rv_sizes</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A 2D tensor representing a list of translated particle events from <cite>cat_particles</cite>. Its 1st dimension size
is equal to the 1st dimension size of <cite>cat_particles</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The specific translation method may vary depending on the distribution class. Therefore, this method serves only
as an API entry point where the specific translation procedure will be looked up in <code class="docutils literal notranslate"><span class="pre">self.dict_2torch_event</span></code>
using the registered distribution class <code class="docutils literal notranslate"><span class="pre">self.dist_class</span></code>. If no entry is found, then will assume no special
translation is necessary and will return the input <cite>cat_particles</cite> as is.</p>
</dd></dl>

<dl class="py method">
<dt id="pysigma.utils.KnowledgeServer.event2cognitive_event">
<code class="sig-name descname">event2cognitive_event</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">particles</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pysigma/utils.html#KnowledgeServer.event2cognitive_event"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysigma.utils.KnowledgeServer.event2cognitive_event" title="Permalink to this definition">¶</a></dt>
<dd><p>Translates joint particle event values from the PyTorch distribution class format to Cognitive format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>particles</strong> (<em>torch.Tensor</em>) – A 2D tensor representing the list of concatenated particle events in PyTorch format.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A 2D tensor representing a list of translated particle events from <cite>cat_particles</cite>. Its 1st dimension size
is equal to the 1st dimension size of <cite>cat_particles</cite>, and 2nd dimension size equal to the sum of rv sizes
in <code class="docutils literal notranslate"><span class="pre">self.rv_sizes</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The specific translation method may vary depending on the distribution class. Therefore, this method serves only
as an API entry point where the specific translation procedure will be looked up in
<code class="docutils literal notranslate"><span class="pre">self.dict_2cognitive_event</span></code> using the registered distribution class <code class="docutils literal notranslate"><span class="pre">self.dist_class</span></code>. If no entry is
found, then will assume no special translation is necessary and will return the input <cite>cat_particles</cite> as is.</p>
</dd></dl>

<dl class="py method">
<dt id="pysigma.utils.KnowledgeServer.combinatorial_cat">
<em class="property">static </em><code class="sig-name descname">combinatorial_cat</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">particles</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pysigma/utils.html#KnowledgeServer.combinatorial_cat"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysigma.utils.KnowledgeServer.combinatorial_cat" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper static method that combinatorially concatenates the list of event particles specified by <cite>particles</cite>.</p>
<p>Returns the contained tensor directly if there is only one entry in <cite>particles</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>particles</strong> (<em>iterable of torch.Tensor</em>) – The list of particles to be concatenated. Each element should be a tensor with a shape of length 2, where
the first dimension is assumed the sample dimension, and second dimension assumed the event dimension.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>The combinatorially concatenated event particle tensor of shape:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">sample_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">...</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">[</span><span class="n">m</span><span class="p">],</span> <span class="n">event_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+...+</span><span class="n">event_size</span><span class="p">[</span><span class="n">m</span><span class="p">]]</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">sample_size[i]</span></code> is the sample size of the <code class="docutils literal notranslate"><span class="pre">i</span></code> th particle, and similarly is <code class="docutils literal notranslate"><span class="pre">event_size[i]</span></code>.
Its total number of dimensions, i.e. <code class="docutils literal notranslate"><span class="pre">.dim()</span></code>, is equal to the number of random variables plus 1.</p>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../examples/index.html" class="btn btn-neutral float-right" title="Example Models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="graphical/other-structural-nodes.html" class="btn btn-neutral float-left" title="Other Structural Nodes" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Jincheng Zhou, Yunzhe Wang, Volkan Ustun, Paul Rosenbloom @ USC Institute for Creative Technologies

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>