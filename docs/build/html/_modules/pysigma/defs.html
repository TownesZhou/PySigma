

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pysigma.defs &mdash; PySigma  documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> PySigma
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Table of Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../introduction/intro.html">Introduction and Tutorials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../introduction/getting-started.html">Getting Started</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../references/index.html">API References</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../references/cognitive.html">Cognitive Language Interface</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../references/cognitive.html#type">Type</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../references/cognitive.html#predicate">Predicate</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../references/cognitive.html#conditional">Conditional</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../references/graphical/index.html">Graphical Architecture</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../references/graphical/data-structures.html">Basic Data Structures</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/data-structures.html#variable-metatypes">Variable Metatypes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/data-structures.html#variable">Variable</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/data-structures.html#message-types">Message Types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/data-structures.html#message">Message</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/data-structures.html#linkdata">LinkData</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../references/graphical/abstract-base-nodes.html">Abstract Base Nodes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/abstract-base-nodes.html#node">Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/abstract-base-nodes.html#factor-node">Factor Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/abstract-base-nodes.html#variable-node">Variable Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/abstract-base-nodes.html#alpha-factor-node">Alpha Factor Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/abstract-base-nodes.html#beta-factor-node">Beta Factor Node</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../references/graphical/predicate-nodes.html">Predicate Subgraph Nodes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/predicate-nodes.html#working-memory-variable-node">Working Memory Variable Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/predicate-nodes.html#long-term-memory-factor-node">Long-Term Memory Factor Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/predicate-nodes.html#perceptual-buffer-node">Perceptual Buffer Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/predicate-nodes.html#working-memory-factor-node">Working Memory Factor Node</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../references/graphical/conditional-nodes.html">Conditional Subgraph Nodes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/conditional-nodes.html#relational-mapping-factor-node">Relational Mapping Factor Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/conditional-nodes.html#expansion-summarization-factor-node">Expansion / Summarization Factor Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/conditional-nodes.html#concatenation-marginalization-transformation-factor-node">Concatenation, Marginalization, &amp; Transformation Factor Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/conditional-nodes.html#event-resolution-factor-node">Event Resolution Factor Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/conditional-nodes.html#beta-join-factor-node">Beta Join Factor Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/conditional-nodes.html#gamma-factor-node">Gamma Factor Node</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../references/graphical/other-structural-nodes.html">Other Structural Nodes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/other-structural-nodes.html#default-factor-node">Default Factor Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../references/graphical/other-structural-nodes.html#default-variable-node">Default Variable Node</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../references/utils.html">Utils</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../references/utils.html#distributionserver">DistributionServer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../references/utils.html#knowledgeserver">KnowledgeServer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/index.html">Example Models</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">PySigma</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>pysigma.defs</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for pysigma.defs</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Basic structures in the graphical architecture</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="k">import</span> <span class="n">Distribution</span><span class="p">,</span> <span class="n">Transform</span>
<span class="kn">from</span> <span class="nn">torch.distributions.constraints</span> <span class="k">import</span> <span class="n">Constraint</span>
<span class="kn">from</span> <span class="nn">torch.nn.functional</span> <span class="k">import</span> <span class="n">l1_loss</span>
<span class="kn">from</span> <span class="nn">enum</span> <span class="k">import</span> <span class="n">Enum</span><span class="p">,</span> <span class="n">Flag</span><span class="p">,</span> <span class="n">auto</span>
<span class="kn">from</span> <span class="nn">collections.abc</span> <span class="k">import</span> <span class="n">Iterable</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="k">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="k">import</span> <span class="n">DistributionServer</span><span class="p">,</span> <span class="n">KnowledgeServer</span>


<span class="c1"># Variable Metatypes and Variable for general inference</span>
<div class="viewcode-block" id="VariableMetatype"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.VariableMetatype">[docs]</a><span class="k">class</span> <span class="nc">VariableMetatype</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Enum class for Variable metatypes.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Indexing</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Particle indexing variable, first dimension of a message</span>
    <span class="n">Relational</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Relational variable, second set of dimensions of a message</span>
    <span class="n">Random</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Random variable, last set of dimensions of a message</span>
    <span class="n">Parameter</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># Parameter variable, last dimensions of a distribution&#39;s parameter tensor</span></div>


<div class="viewcode-block" id="Variable"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Variable">[docs]</a><span class="k">class</span> <span class="nc">Variable</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Variable represented by variable nodes in the graphical architecture. Stores information such as a variable&#39;s</span>
<span class="sd">    meta-type, dimension size, and value constraints (if the variable has Random meta-type).</span>

<span class="sd">    The equality testing is used for matching variables in Alpha-Beta subgraphs. Two variables are equal if and only</span>
<span class="sd">    if ALL of their fields are equal.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    name : str</span>
<span class="sd">        The name of the variable.</span>
<span class="sd">    metatype : {``VariableMetatype.Indexing``, ``VariableMetatype.Relational``, ``VariableMetatype.Random``, ``VariableMetatype.Parameter``}</span>
<span class="sd">        The meta-type of this variable.</span>
<span class="sd">    size : int</span>
<span class="sd">        The size of the message dimension this variable corresponds to.</span>
<span class="sd">    value_constraints : iterable of torch.distributions.constraints.Constraint</span>
<span class="sd">        The set of value constraints that determine the value range (support) of this variable. Specify if and only if</span>
<span class="sd">        variable&#39;s metatype is ``VariableMetatype.Random``.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    name : str</span>
<span class="sd">        Variable name.</span>
<span class="sd">    metatype : {``VariableMetatype.Indexing``, ``VariableMetatype.Relational``, ``VariableMetatype.Random``, ``VariableMetatype.Parameter``}</span>
<span class="sd">        The meta-type of this variable.</span>
<span class="sd">    size : int</span>
<span class="sd">        The size of the message dimension this variable corresponds to.</span>
<span class="sd">    constraints : iterable of torch.distributions.constraints.Constraint</span>
<span class="sd">        The set of value constraints that determine the value range (support) of this variable.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">metatype</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">value_constraints</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">metatype</span><span class="p">,</span> <span class="n">VariableMetatype</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">value_constraints</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">value_constraints</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">)</span> <span class="ow">and</span>
                                             <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">Constraint</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">value_constraints</span><span class="p">))</span>
        <span class="k">assert</span> <span class="p">(</span><span class="n">value_constraints</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="p">(</span><span class="n">metatype</span> <span class="ow">is</span> <span class="n">VariableMetatype</span><span class="o">.</span><span class="n">Random</span><span class="p">)</span>

        <span class="c1"># Variable name, its identity. Used for variable matching. Of type str</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="c1"># Variable meta-type, of type VariableMetatype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metatype</span> <span class="o">=</span> <span class="n">metatype</span>
        <span class="c1"># Variable size. Size of the dimension that the variable corresponds to. Of type int</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="c1"># List of value constraints if the Variable is of Random metatype.</span>
        <span class="c1">#   Useful at Beta-join to select globally valid particle values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">constraints</span> <span class="o">=</span> <span class="n">value_constraints</span>

    <span class="k">def</span> <span class="nf">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="c1"># override so &#39;==&#39; operator test variable equality</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Variable</span><span class="p">)</span>
        <span class="n">val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">name</span> <span class="ow">and</span> \
              <span class="bp">self</span><span class="o">.</span><span class="n">metatype</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">metatype</span> <span class="ow">and</span> \
              <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">size</span> <span class="ow">and</span> \
              <span class="bp">self</span><span class="o">.</span><span class="n">constraints</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">constraints</span>

        <span class="k">return</span> <span class="n">val</span>

    <span class="k">def</span> <span class="nf">__ne__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="c1"># override so &#39;!=&#39; operator test variable inequality</span>
        <span class="k">return</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__eq__</span><span class="p">(</span><span class="n">other</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># override to provide the name as the string representation</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span>

    <span class="k">def</span> <span class="nf">__hash__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># override so that hash value of the string representation of the variable is used</span>
        <span class="k">return</span> <span class="nb">hash</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metatype</span><span class="p">)</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">)</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">constraints</span><span class="p">))</span></div>


<span class="c1"># Generalized message type and message representation</span>
<div class="viewcode-block" id="MessageType"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.MessageType">[docs]</a><span class="k">class</span> <span class="nc">MessageType</span><span class="p">(</span><span class="n">Flag</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Enum class to represent message types</span>

<span class="sd">        The True-valued boolean relationship between types, using the ``in`` operator::</span>

<span class="sd">            Undefined in Undefined == Undefined in Parameter == Undefined in Particles == Undefined in Both == True</span>
<span class="sd">            Parameter in Parameter == Undefined in Both == True</span>
<span class="sd">            Particles in Particles == Undefined in Both == True</span>

<span class="sd">        All other relations are False.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Undefined</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">Parameter</span> <span class="o">=</span> <span class="n">auto</span><span class="p">()</span>
    <span class="n">Particles</span> <span class="o">=</span> <span class="n">auto</span><span class="p">()</span>
    <span class="n">Both</span> <span class="o">=</span> <span class="n">Parameter</span> <span class="o">|</span> <span class="n">Particles</span></div>


<div class="viewcode-block" id="Message"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message">[docs]</a><span class="k">class</span> <span class="nc">Message</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Message to be propagated between nodes in the graphical architecture.</span>

<span class="sd">    The `Message` class is the most fundamental data structure in PySigma that carries the knowledge of a batch of</span>
<span class="sd">    distributions to be processed by downstream graphs.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    msg_type : {``MessageType.Undefined``, ``MessageType.Parameter``, ``MessageType.Particles``, ``MessageType.Both``}</span>
<span class="sd">        The type of this message.</span>
<span class="sd">    batch_shape : torch.Size, optional</span>
<span class="sd">        The size of the batch dimensions. Must specify and be a shape of **at least** length 1, unless the message is</span>
<span class="sd">        representing an identity. See `Notes` section below for more details on identity message.</span>
<span class="sd">    param_shape : torch.Size, optional</span>
<span class="sd">        The size of the parameter dimension of `parameter`. Must specify if `msg_type` is ``MessageType.Parameter`` with</span>
<span class="sd">        a length of **exactly** 1. Default to an empty shape ``torch.Size([])``.</span>
<span class="sd">    sample_shape : torch.Size, optional</span>
<span class="sd">        The size of the sample dimensions of each particle tensor in `particles` respectively in order. Must specify if</span>
<span class="sd">        message type is ``MessageType.Particles``, with a length equal to the number of particle tensors. Default to an</span>
<span class="sd">        empty shape ``torch.Size([])``.</span>
<span class="sd">    event_shape : torch.Size, optional</span>
<span class="sd">        The size of the event dimensions of each particle tensor in `particles` respectively in order. Must specify if</span>
<span class="sd">        message type is ``MessageType.Particles``, with a length equal to the number of particle tensors. Default to an</span>
<span class="sd">        empty shape ``torch.Size([])``.</span>
<span class="sd">    parameter : torch.Tensor or an int of 0, optional</span>
<span class="sd">        The parameter tensor to the batch of distributions this message is encoding. Must specify if the message type is</span>
<span class="sd">        ``MessageType.Parameter``. A torch.Tensor of shape ``batch_shape + param_shape`` if the parameters do not</span>
<span class="sd">        represent the identity in the parameter vector space. Alternatively, can be an int of 0 to specify the identity,</span>
<span class="sd">        in which case it is not necessary to specify `batch_shape`. Default to an int of 0.</span>
<span class="sd">    particles : iterable of torch.Tensor, optional</span>
<span class="sd">        The list of particles representing events w.r.t. each random variable respectively whose collective joint</span>
<span class="sd">        distribution this message is encoding. Must specify if the message type is ``MessageType.Particles``, unless</span>
<span class="sd">        `weight` is 1, in which case the message represents a universal identity in the particles space. The jth</span>
<span class="sd">        entry of the iterable should have shape ``sample_shape[j] + event_shape[j]``.</span>
<span class="sd">    weight : torch.Tensor or an int of 1, optional</span>
<span class="sd">        The importance weight tensor that, when multiplied with the exponential of the cross product of the log sampling</span>
<span class="sd">        densities in `log_densities`, yields the pdf of each combined particle w.r.t. the target distribution that this</span>
<span class="sd">        message is encoding. Must specify if the message type is ``MessageType.Particles``. If the weights are</span>
<span class="sd">        non-uniform, must be a **positively valued** tensor of shape ``batch_shape + sample_shape``. The supplied tensor</span>
<span class="sd">        will be normalized during initialization so that it sums to 1 across the subspace spanned by the sample</span>
<span class="sd">        dimensions. Alternatively, can be an int of 1 to specify the identity (uniform weight), in which case it is not</span>
<span class="sd">        necessary to specify `batch_shape`. Default to 1.</span>
<span class="sd">    log_densities : iterable of torch.Tensor, optional</span>
<span class="sd">        The jth entry in the iterable represents the log pdf of the jth particle in `particles` w.r.t. the (marginal)</span>
<span class="sd">        sampling distribution from which the jth particle was originally drawn. Must specify if the message type is</span>
<span class="sd">        ``MessageType.Particles``, unless `weight` is 1, in which case the message represents a universal identity in</span>
<span class="sd">        the particles space. The jth entry must have shape ``sample_shape[j]``.</span>
<span class="sd">    device : str, optional</span>
<span class="sd">        The device where the tensor components are hosted. ``.to(device)`` will be called on the tensor arguments</span>
<span class="sd">        during initialization. Defaults to &#39;cpu&#39;.</span>
<span class="sd">    **kwargs</span>
<span class="sd">        Other keyword arguments that specify special attributes of the message. Will be deep copied when the message is</span>
<span class="sd">        cloned. Note that any `dist_info` required by DistributionServer regarding the specification of the parameters</span>
<span class="sd">        should be associated with the key ``&quot;dist_info&quot;``.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    type : {``MessageType.Undefined``, ``MessageType.Parameter``, ``MessageType.Particles``, ``MessageType.Both``}</span>
<span class="sd">        Message type.</span>
<span class="sd">    b_shape : torch.Size</span>
<span class="sd">        Batch shape.</span>
<span class="sd">    p_shape : torch.Size</span>
<span class="sd">        Parameter shape.</span>
<span class="sd">    s_shape : torch.Size</span>
<span class="sd">        Sample shape.</span>
<span class="sd">    e_shape : torch.Size</span>
<span class="sd">        Event shape.</span>
<span class="sd">    parameter : torch.Tensor or None</span>
<span class="sd">        Parameter tensor</span>
<span class="sd">    particles : list of torch.Tensor or None</span>
<span class="sd">        Tuple of particle value tensors</span>
<span class="sd">    weight : torch.Tensor or None</span>
<span class="sd">        Particle weight tensor</span>
<span class="sd">    log_densities : list of torch.Tensor or None</span>
<span class="sd">        Tuple of particles log sampling tensors</span>
<span class="sd">    num_rvs : int</span>
<span class="sd">        The number of random variables. Inferred from the length of `particles`.</span>
<span class="sd">    device : str</span>
<span class="sd">        The device where the tensor components are hosted.</span>
<span class="sd">    attr : dict</span>
<span class="sd">        Miscellaneous optional attributes, specified by **kwargs in the constructor.</span>

<span class="sd">    Notes</span>
<span class="sd">    _____</span>
<span class="sd">    In PySigma Graphical Architecture, a message can represent not only a single joint distribution w.r.t. multiple</span>
<span class="sd">    random variables, but a *batch* of such joint distribution instances. The distribution instances in the batch are</span>
<span class="sd">    mutually independent, but may or may not be identically distributed. This batch is managed and indexed by the batch</span>
<span class="sd">    dimensions, specified by `batch_shape`.</span>

<span class="sd">    Depending on how each of the distribution instance is represented, a message can be roughly categorized into two</span>
<span class="sd">    types: *Parameter* type or *Particles* type.</span>

<span class="sd">    1. *Parameter* type: a message of this type encodes a batch of distributions by holding their parameter tensors. The</span>
<span class="sd">       semantics of the parameters depends on the context, e.g. whether they are natural parameters to exponential</span>
<span class="sd">       family distributions or conventional parameters to PyTorch distribution class. For the latter one, the semantics</span>
<span class="sd">       may even be distribution class dependent.</span>

<span class="sd">       Specifying the `parameter` argument only in the constructor is sufficient in terms of the message contents.</span>

<span class="sd">    2. *Particles* type: a message of this type encodes a batch of distributions by a particle list, with the particles</span>
<span class="sd">       being importantly weighted to correctly reflect their pdf w.r.t. to each of the target distribution in the</span>
<span class="sd">       distribution batch. In other words, conceptually, each entry in the particle list is a 3-tuple:</span>
<span class="sd">       ``(x, w_x, log_p(x))`` where ``x`` is the event value, ``log_p(x)`` is the log pdf of ``x`` w.r.t. its sampling</span>
<span class="sd">       distribution ``P(x)``, and ``w_x`` is defined as the ratio of ``Q(x)``, the target distribution pdf, over</span>
<span class="sd">       ``P(x)``. Therefore, the target pdf of ``x`` can be recovered by::</span>

<span class="sd">           Q(x) = w_x * exp(log_p(x))</span>
<span class="sd">           log Q(x) = log(w_X) + log_p(x)</span>

<span class="sd">       Note that a message uses a single list of particles to encode and approximate each and every distribution in the</span>
<span class="sd">       batch. In other words, the set of event values used to represent each distribution instance is the same, but the</span>
<span class="sd">       importance weights assigned to each event value by different distribution instances are different. This is the</span>
<span class="sd">       reason that `weight` tensor should include batch dimensions, whereas particle tensors in `particles` and log</span>
<span class="sd">       sampling density tensors in `log_densities` should not.</span>

<span class="sd">       When there are multiple random variables, each distribution instance in the batch is a joint distribution</span>
<span class="sd">       over all random variables. In this case, each of the entry in the provided `particles` are events w.r.t. each</span>
<span class="sd">       random variable *only*. To represent the joint distributions, a list of *joint* particles will be formed by</span>
<span class="sd">       concatenating the event tensors in `particles` combinatorially, or so to speak, by taking the tensor product.</span>
<span class="sd">       Accordingly, the log sampling density vectors in `log_densities` will be taken cross product to form a higher</span>
<span class="sd">       dimensional sampling density tensors. In this way, the joint particles are effectively arranged in a lattice in</span>
<span class="sd">       the joint event space, therefore easing the marginalization process because we can simply *summarize* over one</span>
<span class="sd">       dimension to achieve the effect of marginalizing over the corresponding random variable.</span>

<span class="sd">       To support the above semantics and computations, all of the arguments `particles`, `weight`, and `log_densities`</span>
<span class="sd">       must be specified in the constructor.</span>

<span class="sd">    A message can encode both type of contents, in which case the message type is ``MessageType.Both``.</span>

<span class="sd">    .. _message-arithmetic-structures-notes:</span>

<span class="sd">    Both types of messages are assumed to reside in certain vector space, and thus the appropriate arithmetic</span>
<span class="sd">    operations -- *Addition* and *Scalar Multiplication* -- are defined and implemented:</span>

<span class="sd">    * For Parameter messages,</span>

<span class="sd">        * *Addition* operation is defined as arithmetic addition on the parameter tensors.</span>
<span class="sd">        * *Scalar multiplication* is defined as arithmetic scalar multiplication with the parameter tensors.</span>
<span class="sd">        * 0 is treated as the identity element.</span>

<span class="sd">    * For Particles messages:</span>

<span class="sd">        * The following two operations are defined as operations on the particle weights, and meaningful only</span>
<span class="sd">          for Particle messages that share the same particle values and the same sampling log densities of the</span>
<span class="sd">          particles, **except for the message that represents particle identity** (See more below). In addition, results</span>
<span class="sd">          from these two operations are normalized so that the weight tensor sums to 1 across the sample dimensions.</span>
<span class="sd">        * *Addition* operation is defined as element-wise multiplication of particle weights tensors, up to a</span>
<span class="sd">          normalization factor.</span>
<span class="sd">        * *Scalar Multiplication* is defined as taking elements of the particle weights tensor to the power</span>
<span class="sd">          of the scalar, up to a normalization factor.</span>
<span class="sd">        * 1 is treated as the identity element for the operations.</span>
<span class="sd">        * Note that it is provably correct that the weighs with above operations form a vector space. The proof idea is</span>
<span class="sd">          to consider the log quotient space over one dimension, which reduces to standard real space with one less</span>
<span class="sd">          dimension.</span>

<span class="sd">    Regarding the identity messages:</span>

<span class="sd">    * The ``MessageType.Parameter`` type identity message is one whose ``parameter`` field is 0.</span>
<span class="sd">    * The ``MessageType.Particles`` type identity message is one whose ``weight`` field is 1, **regardless of its</span>
<span class="sd">      particle values ``particles`` or sampling log densities ``log_densities``.</span>
<span class="sd">    * The ``MessageType.Both`` type identity message is the composition of the above two identity messages.</span>

<span class="sd">    Accordingly, the &#39;+&#39; and &#39;*&#39; operator are overloaded according the to the specifications above.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">msg_type</span><span class="p">,</span>
                 <span class="n">batch_shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([]),</span>
                 <span class="n">param_shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([]),</span> <span class="n">sample_shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([]),</span> <span class="n">event_shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([]),</span>
                 <span class="n">parameter</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">particles</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">log_densities</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">msg_type</span><span class="p">,</span> <span class="n">MessageType</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param_shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">param_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">,</span> \
            <span class="s2">&quot;`param_shape` must be a torch.Size of length at most 1. Found </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">param_shape</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sample_shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">event_shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">event_shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample_shape</span><span class="p">),</span> \
            <span class="s2">&quot;`sample_shape` and `event_shape` must both be torch.Size with the same length. Found &quot;</span> \
            <span class="s2">&quot;(sample_shape, event_shape) = (</span><span class="si">{}</span><span class="s2">, </span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sample_shape</span><span class="p">,</span> <span class="n">event_shape</span><span class="p">)</span>

        <span class="k">assert</span> <span class="n">parameter</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">parameter</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">particles</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">particles</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">)</span> <span class="ow">and</span>
                                     <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">particles</span><span class="p">))</span>
        <span class="k">assert</span> <span class="n">weight</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">log_densities</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">log_densities</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">)</span> <span class="ow">and</span>
                                         <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">log_densities</span><span class="p">))</span>

        <span class="c1"># Message type, of type MessageType</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="o">=</span> <span class="n">msg_type</span>
        <span class="c1"># Device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="c1"># Parameter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span> <span class="o">=</span> <span class="n">parameter</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">parameter</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="k">else</span> <span class="n">parameter</span>
        <span class="c1"># Particle list</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">particles</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">particles</span><span class="p">)</span> <span class="k">if</span> <span class="n">particles</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="k">else</span> <span class="n">weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">log_densities</span><span class="p">)</span> <span class="k">if</span> <span class="n">log_densities</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> \
            <span class="kc">None</span>
        <span class="c1"># Additional important attributes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attr</span> <span class="o">=</span> <span class="n">kwargs</span>
        <span class="c1"># Shapes.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span> <span class="o">=</span> <span class="n">batch_shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span> <span class="o">=</span> <span class="n">param_shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span> <span class="o">=</span> <span class="n">sample_shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span> <span class="o">=</span> <span class="n">event_shape</span>
        <span class="c1"># Number of random variabels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_rvs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">)</span>

        <span class="c1"># Check whether necessary arguments are provided</span>
        <span class="k">if</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Parameter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> \
                <span class="s2">&quot;For a Parameter message, the length of the parameter shape must be exactly 1. Found param_shape = </span><span class="si">{}</span><span class="s2">&quot;</span> \
                <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">)</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> \
                <span class="s2">&quot;Must specify `parameter` for a Parameter message.&quot;</span>
        <span class="k">if</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">,</span> \
                <span class="s2">&quot;For a Particles message, the length of the sample / event shape must be at least 1. Found &quot;</span> \
                <span class="s2">&quot;sample_shape = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">)</span>
            <span class="c1"># does not care whether particles is specified if it&#39;s a particles identity</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> \
                <span class="s2">&quot;Must specify the particle values tensor via `particles` for a Particles message, unless the message &quot;</span> \
                <span class="s2">&quot;represents the identity.&quot;</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> \
                <span class="s2">&quot;Must specify the particle weight tensor via `weight` for a Particles message, unless the message &quot;</span> \
                <span class="s2">&quot;represents the identity.&quot;</span>
            <span class="c1"># similarly does not care if it&#39;s identity</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> \
                <span class="s2">&quot;Must specify the particles log density tensor via `log_densities` for a Particles message, unless &quot;</span> \
                <span class="s2">&quot;the message represents the identity.&quot;</span>

        <span class="c1"># Check shape and values. Adjust if necessary</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameter</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># Parameter tensor should have shape (b_shape + p_shape)</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> \
                <span class="s2">&quot;When specified, the parameter tensor should have shape (batch_shape + param_shape). Expect </span><span class="si">{}</span><span class="s2">, but &quot;</span> \
                <span class="s2">&quot;instead found </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">particles</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># jth particle tensor should have shape (s_shape[j] + e_shape[j])</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_rvs</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">),</span> \
                <span class="s2">&quot;When specified, the number of entries in the iterable `particles` must equal to the length of &quot;</span> \
                <span class="s2">&quot;`sample_shape` and `event_shape`. Expect </span><span class="si">{}</span><span class="s2">, but instead found </span><span class="si">{}</span><span class="s2"> entries.&quot;</span> \
                <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_rvs</span><span class="p">)</span>
            <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">[</span><span class="n">j</span><span class="p">]])</span> <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span>
                       <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">)),</span> \
                <span class="s2">&quot;When specified, The j-th particle tensor specified in the iterable `particles` should have shape &quot;</span> \
                <span class="s2">&quot;(sample_shape[j] + event_shape[j]). Expect shapes </span><span class="si">{}</span><span class="s2">, but instead found particle tensor shapes </span><span class="si">{}</span><span class="s2">.&quot;</span> \
                <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">[</span><span class="n">j</span><span class="p">]])</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_rvs</span><span class="p">)),</span>
                        <span class="nb">list</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># Weights tensor should have shape (b_shape + s_shape)</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> \
                <span class="s2">&quot;When specified, the particles weight should have shape (batch_shape + sample_shape). Expect </span><span class="si">{}</span><span class="s2">, but &quot;</span> \
                <span class="s2">&quot;intead found </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="c1"># Check that values are non-negative</span>
            <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">),</span> <span class="s2">&quot;Found negative values in particle weights. Minimum value: </span><span class="si">{}</span><span class="s2">&quot;</span> \
                <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">))</span>
            <span class="c1"># Normalize the values so that weights sum to 1 across sample dimension</span>
            <span class="n">sample_dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">)))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">sample_dims</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># jth log density tensor vector should have shape (s_shape[j])</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_rvs</span><span class="p">,</span> \
                <span class="s2">&quot;When specified, the iterable `log_densities` must have the same number of entries as `particles`. &quot;</span> \
                <span class="s2">&quot;Found </span><span class="si">{}</span><span class="s2"> entries in `particles`, but </span><span class="si">{}</span><span class="s2"> entries in `log_densities`&quot;</span> \
                <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_rvs</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span><span class="p">))</span>
            <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">[</span><span class="n">j</span><span class="p">]])</span> <span class="o">==</span> <span class="n">d</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span><span class="p">)),</span> \
                <span class="s2">&quot;When specified, the j-th log density tensor specified in the iterable `log_densities` should have &quot;</span> \
                <span class="s2">&quot;shape (sample_shape[j]). Expect shapes </span><span class="si">{}</span><span class="s2">, but instead found log density tensor shapes </span><span class="si">{}</span><span class="s2">.&quot;</span> \
                <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_rvs</span><span class="p">)),</span> <span class="nb">list</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span><span class="p">))</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Member properties</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">isid</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Whether `self` is an identity message.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">MessageType</span><span class="o">.</span><span class="n">Parameter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="ow">or</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">)</span> <span class="ow">and</span> \
               <span class="p">(</span><span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> \
               <span class="p">(</span><span class="n">MessageType</span><span class="o">.</span><span class="n">Parameter</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Shape of the message. Equivalent to calling size()</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overload arithmetic operators</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Message.__add__"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.__add__">[docs]</a>    <span class="k">def</span> <span class="nf">__add__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Overloads the addition operation ``+``.</span>

<span class="sd">        Implements the semantics of addition operation as in vector spaces. The computational operations used to</span>
<span class="sd">        implement the semantics are different for different message contents. See</span>
<span class="sd">        :ref:`Message class notes on arithmetic structures&lt;message-arithmetic-structures-notes&gt;`</span>
<span class="sd">        for more details.</span>

<span class="sd">        Only messages with compatible types can be added. This means a ``MessageType.Parameter`` type message can only</span>
<span class="sd">        be added with one of type ``MessageType.Parameter`` or ``MessageType.Both``, and similarly a</span>
<span class="sd">        ``MessageType.Particles`` type message can only be added with one of type ``MessageType.Particles`` or</span>
<span class="sd">        ``MessageType.Both``. ``MessageType.Both`` type message can be added with any other type except</span>
<span class="sd">        ``MessageType.Undefined``, and in any case a ``MessageType.Undefined`` type message cannot be added.</span>

<span class="sd">        There are more restrictions for ``MessageType.Particles`` type messages. Messages of such type can only be</span>
<span class="sd">        added together if their ``particles`` and ``log_densities`` fields are equal, unless one (or both) is the</span>
<span class="sd">        identity Particles message.</span>

<span class="sd">        If two messages with compatible but not identical types are added together, the resulting message will have the</span>
<span class="sd">        smaller type, meaning only the common components will be added. For example, the result of adding a</span>
<span class="sd">        ``MessageType.Parameter`` type message with a ``MessageType.Both`` type message is a ``MessageType.Parameter``</span>
<span class="sd">        type message. But if two ``MessageType.Both`` type messages are added, the resulting message will also have</span>
<span class="sd">        type ``MessageType.Both``, containing both parameter and particles components.</span>

<span class="sd">        Note that the identity messages (Parameter message with ``parameter == 0``, Particles message with</span>
<span class="sd">        ``weight == 1``, or Both message with both conditions) are assumed universal, i.e., they can be added with</span>
<span class="sd">        any other message that has a compatible type but may or may not have a compatible shape. The resulting message</span>
<span class="sd">        will be the other message itself. If both `self` and `other` are identity messages, the returning message will</span>
<span class="sd">        be the identity message with the larger type.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        other : Message</span>
<span class="sd">            The other message instance to be added together with `self`. It should have a compatible message type with</span>
<span class="sd">            `self`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            The new message as a result of the summation.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        AssertionError</span>
<span class="sd">            If `other`&#39;s message type is incompatible with `self`.</span>
<span class="sd">        AssertionError</span>
<span class="sd">            If either `self` or `other`&#39;s message type is ``MessageType.Undefined``.</span>
<span class="sd">        AssertionError</span>
<span class="sd">            If contents of `self` and `other` have conflicting shapes, when both `self` and `other` are not identity</span>
<span class="sd">            messages.</span>
<span class="sd">        AssertionError</span>
<span class="sd">            If `self` and `other` have particles message contents to be added, but their particle values do not match,</span>
<span class="sd">            or their log sampling density tensors do not match.</span>

<span class="sd">        Warnings</span>
<span class="sd">        --------</span>
<span class="sd">        The attribute dictionaries ``self.attr`` and ``other.attr`` from the two messages will be merged. However, if</span>
<span class="sd">        there exist conflicting entries, some would be overwritten by the other. In general, it is the last operand</span>
<span class="sd">        in the expression, i.e., `other`, whose attribute entries persist, but this behavior should not be counted on.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Message</span><span class="p">),</span> <span class="s2">&quot;Message can only be added with another Message&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="n">other</span><span class="o">.</span><span class="n">type</span> <span class="ow">or</span> <span class="n">other</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> \
            <span class="s2">&quot;Only compatible types of messages can be added. First operand has type &#39;</span><span class="si">{}</span><span class="s2">&#39;,  while the second one has &quot;</span> \
            <span class="s2">&quot;type &#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>
        <span class="c1"># Get the small type and large type</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="n">other</span><span class="o">.</span><span class="n">type</span><span class="p">:</span>
            <span class="n">s_type</span><span class="p">,</span> <span class="n">l_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">type</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">s_type</span><span class="p">,</span> <span class="n">l_type</span> <span class="o">=</span> <span class="n">other</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span>
        <span class="c1"># Undefined type cannot be added</span>
        <span class="k">assert</span> <span class="n">s_type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Undefined</span><span class="p">,</span> \
            <span class="s2">&quot;Message of undefined type cannot be added. First operand has type &#39;</span><span class="si">{}</span><span class="s2">&#39;, while the second one has type &quot;</span> \
            <span class="s2">&quot;&#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>

        <span class="c1"># Check if either self or other is an identity message. If so, return the other message directly.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">isid</span> <span class="ow">and</span> <span class="n">other</span><span class="o">.</span><span class="n">isid</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="n">other</span><span class="o">.</span><span class="n">type</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">other</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">isid</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">other</span>
        <span class="k">elif</span> <span class="n">other</span><span class="o">.</span><span class="n">isid</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>

        <span class="n">param_msg</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">ptcl_msg</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># Addition for Parameter type</span>
        <span class="k">if</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Parameter</span> <span class="ow">in</span> <span class="n">s_type</span><span class="p">:</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">b_shape</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> \
                <span class="s2">&quot;Only Messages with the same shape can be added together. The messages being added are of Parameter &quot;</span> \
                <span class="s2">&quot;type. Found first message with (batch_shape, param_shape) = &#39;</span><span class="si">{}</span><span class="s2">&#39;, and second message with &quot;</span> \
                <span class="s2">&quot;(batch_shape, param_shape) = &#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">),</span> <span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">p_shape</span><span class="p">))</span>
            <span class="c1"># Tensor addition</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span> <span class="o">+</span> <span class="n">other</span><span class="o">.</span><span class="n">parameter</span>

            <span class="n">param_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">batch_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">param_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="n">parameters</span><span class="o">=</span><span class="n">new_parameter</span><span class="p">)</span>

        <span class="c1"># Addition for Particles type</span>
        <span class="k">if</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span> <span class="ow">in</span> <span class="n">s_type</span><span class="p">:</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">b_shape</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">s_shape</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span> \
                <span class="s2">&quot;Only Messages with the same shape can be added together. The messages being added are of Particles &quot;</span> \
                <span class="s2">&quot;type. Found first message with (batch_shape, sample_shape, event_shape) = &#39;</span><span class="si">{}</span><span class="s2">&#39;, and second message &quot;</span> \
                <span class="s2">&quot;with (batch_shape, sample_shape, event_shape) = &#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span> \
                    <span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">),</span> <span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">e_shape</span><span class="p">))</span>
            <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">self_p</span><span class="p">,</span> <span class="n">other_p</span><span class="p">)</span> <span class="k">for</span> <span class="n">self_p</span><span class="p">,</span> <span class="n">other_p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">particles</span><span class="p">)),</span> \
                <span class="s2">&quot;For particle messages, only ones with matching particle values can be added together. &quot;</span>
            <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">self_d</span><span class="p">,</span> <span class="n">other_d</span><span class="p">)</span> <span class="k">for</span> <span class="n">self_d</span><span class="p">,</span> <span class="n">other_d</span> <span class="ow">in</span>
                       <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">log_densities</span><span class="p">)),</span> \
                <span class="s2">&quot;For particle messages, only ones with matching log sampling densities can be added together&quot;</span>

            <span class="c1"># Take element-wise product</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">*</span> <span class="n">other</span><span class="o">.</span><span class="n">weight</span>
            <span class="c1"># Clone self tensor contents</span>
            <span class="n">cloned_particles</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">)</span>
            <span class="n">cloned_log_densities</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span><span class="p">)</span>
            <span class="n">ptcl_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="n">s_type</span><span class="p">,</span>
                               <span class="n">batch_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">sample_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">event_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                               <span class="n">particles</span><span class="o">=</span><span class="n">cloned_particles</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">new_weights</span><span class="p">,</span> <span class="n">log_densities</span><span class="o">=</span><span class="n">cloned_log_densities</span><span class="p">)</span>

        <span class="c1"># Compose if we are adding two Both type messages, otherwise return the proper one</span>
        <span class="k">if</span> <span class="n">param_msg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ptcl_msg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">param_msg</span><span class="p">,</span> <span class="n">ptcl_msg</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">param_msg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">new_msg</span> <span class="o">=</span> <span class="n">param_msg</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_msg</span> <span class="o">=</span> <span class="n">ptcl_msg</span>

        <span class="c1"># Merge and set attributes</span>
        <span class="n">new_msg</span><span class="o">.</span><span class="n">attr</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">,</span> <span class="o">**</span><span class="n">other</span><span class="o">.</span><span class="n">attr</span><span class="p">}</span>

        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.__iadd__"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.__iadd__">[docs]</a>    <span class="k">def</span> <span class="nf">__iadd__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Overloads self-addition operator ``+=``.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        __add__</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__add__</span><span class="p">(</span><span class="n">other</span><span class="p">)</span></div>

<div class="viewcode-block" id="Message.__mul__"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.__mul__">[docs]</a>    <span class="k">def</span> <span class="nf">__mul__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Overloads multiplication operator ``*``.</span>

<span class="sd">        Implements the semantics of scalar multiplication operation as in vector spaces. The computational operations</span>
<span class="sd">        used to implement the semantics are different for different message contents. See</span>
<span class="sd">        :ref:`Message class notes regarding arithmetic structures&lt;message-arithmetic-structures-notes&gt;`</span>
<span class="sd">        for more details.</span>

<span class="sd">        Message of type ``MessageType.Undefined`` cannot be scalar multiplied.</span>

<span class="sd">        If `self` is an identity message, returns `self` unchanged directly.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        other : int, float, or torch.Tensor</span>
<span class="sd">            The scalar to the multiplication. If a torch.Tensor, can be a singleton tensor representing a single scalar,</span>
<span class="sd">            or a tensor of shape ``batch_shape`` representing a batched scalars, assigning a different scalar value to</span>
<span class="sd">            each distribution instance in the batch.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            The new message as a result of the scalar multiplication.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        AssertionError</span>
<span class="sd">            Attempting to scalar multiply a message of type ``MessageType.Undefined``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)),</span> \
            <span class="s2">&quot;Message can only be multiplied with a scalar. The scalar can be of int, float or torch.Tensor type. &quot;</span> \
            <span class="s2">&quot;Instead found: &#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">other</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">assert</span> <span class="n">other</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([])</span> <span class="ow">or</span> <span class="n">other</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> \
                <span class="s2">&quot;If the scalar is a torch.Tensor, must be either a singleton tensor or a tensor with the same shape &quot;</span> \
                <span class="s2">&quot;as the Message&#39;s batch shape: &#39;</span><span class="si">{}</span><span class="s2">&#39;. Instead found: &#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="c1"># Undefined type cannot be scalar multiplied</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Undefined</span><span class="p">,</span> \
            <span class="s2">&quot;Message of undefined type cannot be scalar multiplied. The message has type &#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span> \
            <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>

        <span class="c1"># If self is identity, return directly.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">isid</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>

        <span class="c1"># Expand scalar tensor dimension if it is a batched scalars</span>
        <span class="n">b_p_other</span> <span class="o">=</span> <span class="n">other</span>
        <span class="n">b_s_other</span> <span class="o">=</span> <span class="n">other</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">other</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Parameter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">:</span>
                <span class="n">b_p_other</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">b_p_other</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">)):</span>
                    <span class="n">b_s_other</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">b_s_other</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Scalar multiplication for Parameter messages</span>
        <span class="n">new_msg</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Parameter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">:</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="n">b_p_other</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span>
            <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">batch_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">param_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="n">parameters</span><span class="o">=</span><span class="n">new_parameter</span><span class="p">)</span>

        <span class="c1"># Scalar multiplication for Particles messages</span>
        <span class="k">if</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">:</span>
            <span class="c1"># The result of scalar multiplication with uniform weights is still uniform, so only process non-uniform</span>
            <span class="c1">#   weights</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="c1"># Extract int/float from singleton scalar tensor</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b_s_other</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">b_s_other</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">b_s_other</span> <span class="o">=</span> <span class="n">b_s_other</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="c1"># Take weights tensor to the power of the scaler</span>
                <span class="n">new_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">b_s_other</span><span class="p">)</span>

            <span class="c1"># Clone tensor contents</span>
            <span class="n">cloned_particles</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">)</span>
            <span class="n">cloned_log_densities</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span><span class="p">)</span>
            <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                              <span class="n">batch_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">sample_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">event_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                              <span class="n">particles</span><span class="o">=</span><span class="n">cloned_particles</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">log_densities</span><span class="o">=</span><span class="n">cloned_log_densities</span><span class="p">,</span>
                              <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.__imul__"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.__imul__">[docs]</a>    <span class="k">def</span> <span class="nf">__imul__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Overloads self-multiplication operator ``*=``.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        __mul__</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__mul__</span><span class="p">(</span><span class="n">other</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># if self.type == MessageType.Parameter:</span>
        <span class="c1">#     b_shape_str = str(list(self.b_shape))</span>
        <span class="c1">#     p_shape_str = str(list(self.p_shape))</span>
        <span class="c1">#     parameters_str = str(list(self.parameter.tolist()))</span>
        <span class="c1">#</span>
        <span class="c1">#     return f&quot;Type: Parameter\nBatch_Shape: {b_shape_str}\nParameter_Shape: {p_shape_str}\n&quot; \</span>
        <span class="c1">#            f&quot;Parameters{parameters_str}&quot;</span>
        <span class="c1">#</span>
        <span class="c1"># else:</span>
        <span class="c1">#     s_shape_str = str(list(self.s_shape))</span>
        <span class="c1">#     b_shape_str = str(list(self.b_shape))</span>
        <span class="c1">#     e_shape_str = str(list(self.e_shape))</span>
        <span class="c1">#     particles_str = str(list(self.particles.tolist()))</span>
        <span class="c1">#     weights_str = str(list(self.weights.tolist()))</span>
        <span class="c1">#     log_density_str = str(list(self.log_density.tolist()))</span>
        <span class="c1">#</span>
        <span class="c1">#     return f&quot;Type: Particles\nSample_Shape: {s_shape_str}\nBatch_Shape: {b_shape_str}\n&quot; \</span>
        <span class="c1">#            f&quot;Event_Shape: {e_shape_str}\nParticles: {particles_str}\n&quot; \</span>
        <span class="c1">#            f&quot;Weights: {weights_str}\nLog_Density: {log_density_str}&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;String representation for Message instance is yet to be implemented.&quot;</span><span class="p">)</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Static utility methods of Message class</span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="Message.compose"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.compose">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">compose</span><span class="p">(</span><span class="n">msg1</span><span class="p">,</span> <span class="n">msg2</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Composes a ``MessageType.Particles`` message with a ``MessageType.Parameters`` message to return a</span>
<span class="sd">        ``MessageType.Both`` message that contain all components from both messages.</span>

<span class="sd">        Both `msg1` and `msg2` cannot be identity messages.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        msg1 : Message</span>
<span class="sd">            The first message to be composed. Its type must be either `MessageType.Particles`` or</span>
<span class="sd">            ``MessageType.Parameters``, but must be different from that of `msg2`.</span>
<span class="sd">        msg2 : Message</span>
<span class="sd">            The second message to be composed. Its type must be either `MessageType.Particles`` or</span>
<span class="sd">            ``MessageType.Parameters``, but must be different from that of `msg1`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            A message with type ``MessageType.Both`` that contains all components from both `msg1` and `msg2`.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        AssertionError</span>
<span class="sd">            If `msg1` and `msg2` have conflicting attributes, such as batch shape.</span>

<span class="sd">        Warnings</span>
<span class="sd">        --------</span>
<span class="sd">        The attribute dictionaries ``msg1.attr`` and ``msg2.attr`` will be merged. If there exists conflicting entries</span>
<span class="sd">        (key-value pairs with same key but different values), those from ``msg2.attr`` will overwrite those from</span>
<span class="sd">        ``msg1.attr``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">msg1</span><span class="p">,</span> <span class="n">Message</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">msg2</span><span class="p">,</span> <span class="n">Message</span><span class="p">)</span>
        <span class="k">assert</span> <span class="p">{</span><span class="n">msg1</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">msg2</span><span class="o">.</span><span class="n">type</span><span class="p">}</span> <span class="o">==</span> <span class="p">{</span><span class="n">MessageType</span><span class="o">.</span><span class="n">Parameter</span><span class="p">,</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span><span class="p">}</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">msg1</span><span class="o">.</span><span class="n">isid</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">msg2</span><span class="o">.</span><span class="n">isid</span><span class="p">,</span> \
            <span class="s2">&quot;`msg1` and `msg2` both cannot be identity messages when composing new messages.&quot;</span>

        <span class="n">param_msg</span> <span class="o">=</span> <span class="n">msg1</span> <span class="k">if</span> <span class="n">msg1</span><span class="o">.</span><span class="n">type</span> <span class="ow">is</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Parameter</span> <span class="k">else</span> <span class="n">msg2</span>
        <span class="n">ptcl_msg</span> <span class="o">=</span> <span class="n">msg1</span> <span class="k">if</span> <span class="n">msg1</span><span class="o">.</span><span class="n">type</span> <span class="ow">is</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span> <span class="k">else</span> <span class="n">msg2</span>
        <span class="c1"># Check consistency of other Message attributes</span>
        <span class="k">assert</span> <span class="n">param_msg</span><span class="o">.</span><span class="n">b_shape</span> <span class="o">==</span> <span class="n">ptcl_msg</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> \
            <span class="s2">&quot;Attempting to compose a parameter message with a particles message, but found conflicting batch shapes: &quot;</span> \
            <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">msg1</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">msg2</span><span class="o">.</span><span class="n">b_shape</span><span class="p">])</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="n">MessageType</span><span class="o">.</span><span class="n">Both</span><span class="p">,</span>
                          <span class="n">batch_shape</span><span class="o">=</span><span class="n">param_msg</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">param_shape</span><span class="o">=</span><span class="n">param_msg</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span>
                          <span class="n">sample_shape</span><span class="o">=</span><span class="n">ptcl_msg</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">event_shape</span><span class="o">=</span><span class="n">ptcl_msg</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">parameter</span><span class="o">=</span><span class="n">param_msg</span><span class="o">.</span><span class="n">parameter</span><span class="p">,</span>
                          <span class="n">particles</span><span class="o">=</span><span class="n">ptcl_msg</span><span class="o">.</span><span class="n">particles</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">ptcl_msg</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">log_densities</span><span class="o">=</span><span class="n">ptcl_msg</span><span class="o">.</span><span class="n">log_densities</span><span class="p">,</span>
                          <span class="o">**</span><span class="p">{</span><span class="o">**</span><span class="n">msg1</span><span class="o">.</span><span class="n">attr</span><span class="p">,</span> <span class="o">**</span><span class="n">msg2</span><span class="o">.</span><span class="n">attr</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        General utility member methods</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Message.size"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.size">[docs]</a>    <span class="k">def</span> <span class="nf">size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a tuple of the message&#39;s shapes: ``(batch_shape, param_shape, sample_shape, event_shape)``</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple of torch.Size</span>
<span class="sd">            A tuple of the message&#39;s shapes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span></div>

<div class="viewcode-block" id="Message.same_size_as"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.same_size_as">[docs]</a>    <span class="k">def</span> <span class="nf">same_size_as</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Check if self has the same shape as the other message.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        bool</span>
<span class="sd">            True if self has the same shape as the other message.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Message</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">size</span><span class="p">()</span></div>

<div class="viewcode-block" id="Message.same_particles_as"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.same_particles_as">[docs]</a>    <span class="k">def</span> <span class="nf">same_particles_as</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Check if `self` has the same particles as the other message. This include checking the list of particle value</span>
<span class="sd">        tensors as well as checking the list of particle log sampling density tensors.</span>

<span class="sd">        .. note::</span>

<span class="sd">           Will always return ``False`` if `self` or `other` is not Particles message.</span>

<span class="sd">        .. note::</span>

<span class="sd">           Will always return ``True`` if both `self` and `other` are Particles message and one (or both) is the</span>
<span class="sd">           identity.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        other : Message</span>
<span class="sd">            The other message.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        bool</span>
<span class="sd">            True if `self` has the same particles as the `other` message.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Message</span><span class="p">)</span>
        <span class="c1"># Return False is message is not event Particles message</span>
        <span class="k">if</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="ow">or</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">other</span><span class="o">.</span><span class="n">type</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="c1"># Return True if one is the identity</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">isid</span> <span class="ow">or</span> <span class="n">other</span><span class="o">.</span><span class="n">isid</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="c1"># Otherwise, if number of random variables are different, return False directly</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_rvs</span> <span class="o">!=</span> <span class="n">other</span><span class="o">.</span><span class="n">num_rvs</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="n">same</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="c1"># Check list of particle value tensors</span>
        <span class="k">for</span> <span class="n">s_p</span><span class="p">,</span> <span class="n">o_p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">particles</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">s_p</span><span class="p">,</span> <span class="n">o_p</span><span class="p">):</span>
                <span class="n">same</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="c1"># Check list of sampling log density tensors</span>
        <span class="k">for</span> <span class="n">s_d</span><span class="p">,</span> <span class="n">o_d</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">log_densities</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">s_d</span><span class="p">,</span> <span class="n">o_d</span><span class="p">):</span>
                <span class="n">same</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">return</span> <span class="n">same</span></div>

<div class="viewcode-block" id="Message.diff_param"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.diff_param">[docs]</a>    <span class="k">def</span> <span class="nf">diff_param</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute the difference between the parameters of `self` and `other`.</span>

<span class="sd">        Returns a batch average L2 distance between the two parameters. Since parameters have shape</span>
<span class="sd">        ``(batch_shape, param_shape)``, with ``param_shape`` of exactly length 1, the L2 distance is calculated along</span>
<span class="sd">        ``dim=-1``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        other : Message</span>
<span class="sd">            The other message.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor or 0</span>
<span class="sd">            The batch average L2 distance.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        AssertionError</span>
<span class="sd">            If `self` and/or `other` do not have parameters.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        The L2 norm computation:</span>
<span class="sd">        `torch.norm() &lt;https://pytorch.org/docs/stable/torch.html#torch.norm&gt;`_.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Message</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Parameter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="ow">and</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Parameter</span> <span class="ow">in</span> <span class="n">other</span><span class="o">.</span><span class="n">type</span>

        <span class="c1"># Returns 0 if both are identity</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">isid</span> <span class="ow">and</span> <span class="n">other</span><span class="o">.</span><span class="n">isid</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>

        <span class="c1"># Parameter has shape (batch_shape, param_shape), with param_shape of exactly length one</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span> <span class="o">-</span> <span class="n">other</span><span class="o">.</span><span class="n">parameter</span>
        <span class="n">val</span> <span class="o">=</span> <span class="n">diff</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">val</span></div>

<div class="viewcode-block" id="Message.diff_weight"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.diff_weight">[docs]</a>    <span class="k">def</span> <span class="nf">diff_weight</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute the difference between the weight of `self` and `other`.</span>

<span class="sd">        Returns a mean element-wise absolute value difference between the two weight tensors.</span>

<span class="sd">        Note that calculating the difference of weights only makes sense if both messages have the *same* particle value</span>
<span class="sd">        tensors and particle log sampling density tensors. Therefore, `same_particles_as()` will first be called for a</span>
<span class="sd">        sanity check. An assertion error will be raised if `same_particles_as()` returns ``False``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        other : Message</span>
<span class="sd">            The other message</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor or 0</span>
<span class="sd">            The batch average cosine similarity.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        AssertionError</span>
<span class="sd">            If `self` and/or `other` do not have particles.</span>
<span class="sd">        AssertionError</span>
<span class="sd">            If `self` does not have the same particle values and log sampling densities as `other`.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        The cosine similarity computation:</span>
<span class="sd">        `torch.nn.functional.cosine_similarity() &lt;https://pytorch.org/docs/stable/nn.functional.html?highlight=cosine#torch.nn.functional.cosine_similarity&gt;`_.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Message</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="ow">and</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span> <span class="ow">in</span> <span class="n">other</span><span class="o">.</span><span class="n">type</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">same_particles_as</span><span class="p">(</span><span class="n">other</span><span class="p">)</span>

        <span class="c1"># Returns 0 if both are identity</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">isid</span> <span class="ow">and</span> <span class="n">other</span><span class="o">.</span><span class="n">isid</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        <span class="c1"># If one is identity, create a uniform weight tensor of the same size as the other message&#39;s weight tensor</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">isid</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">/</span> <span class="n">other</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
        <span class="n">x2</span> <span class="o">=</span> <span class="n">other</span><span class="o">.</span><span class="n">weight</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">other</span><span class="o">.</span><span class="n">isid</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>

        <span class="n">val</span> <span class="o">=</span> <span class="n">l1_loss</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">val</span></div>

<div class="viewcode-block" id="Message.reduce_type"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.reduce_type">[docs]</a>    <span class="k">def</span> <span class="nf">reduce_type</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">msg_type</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a reduced `msg_type` type message from `self`, where irrelevant components w.r.t. &#39;msg_type&#39; in</span>
<span class="sd">        `self` is removed, and only relevant components are retained and cloned.</span>

<span class="sd">        The target message type must be either ``MessageType.Parameter`` or ``MessageType.Particles``.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        msg_type : {``MessageType.Parameter``, ``MessageType.Particles``}</span>
<span class="sd">            The message type of the returned reduced message.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            The reduced message from `self`.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        AssertionError</span>
<span class="sd">            If target message type specified by `msg_type` is not compatible with `self` type.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">msg_type</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> \
            <span class="s2">&quot;Target message type &#39;</span><span class="si">{}</span><span class="s2">&#39; is not compatible with self message type &#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">msg_type</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">msg_type</span> <span class="ow">is</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Parameter</span> <span class="ow">or</span> <span class="n">msg_type</span> <span class="ow">is</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span><span class="p">,</span> \
            <span class="s2">&quot;The target message type can only be Parameter or Particles. &quot;</span>

        <span class="k">if</span> <span class="n">msg_type</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>

        <span class="c1"># First clone content</span>
        <span class="n">cloned_msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">msg_type</span> <span class="o">==</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Parameter</span><span class="p">:</span>
            <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">batch_shape</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">param_shape</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span>
                              <span class="n">parameters</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">parameter</span><span class="p">,</span> <span class="o">**</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">batch_shape</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">sample_shape</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span>
                              <span class="n">event_shape</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span> <span class="n">particles</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">particles</span><span class="p">,</span>
                              <span class="n">weights</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">log_densities</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">log_densities</span><span class="p">,</span> <span class="o">**</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.clone"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.clone">[docs]</a>    <span class="k">def</span> <span class="nf">clone</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a cloned message from self.</span>

<span class="sd">        Guarantees that every content is deep-copied. Tensors will be cloned and dictionaries will be deep-copied.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            A cloned and deep-copied message of `self`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span>
        <span class="n">particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">log_densities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span>
        <span class="n">attr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attr</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">parameters</span> <span class="o">=</span> <span class="n">parameters</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">particles</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">particles</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">particles</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">log_densities</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">log_densities</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">log_densities</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">attr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">attr</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">parameters</span><span class="p">,</span> <span class="n">particles</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">log_densities</span><span class="p">,</span> <span class="o">**</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.to_device"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.to_device">[docs]</a>    <span class="k">def</span> <span class="nf">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a version of `self` where the tensor components are hosted on the specified `device`.</span>

<span class="sd">        Per PyTorch design, the original tensors will be returned without copying if target `device` is the current</span>
<span class="sd">        device, otherwise a copied version will be returned.</span>

<span class="sd">        .. note::</span>

<span class="sd">           Any tensor stored in the optional attribute dictionary ``self.attr`` will NOT be inspected and be moved to</span>
<span class="sd">           the target device.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        device : str</span>
<span class="sd">            The target device</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            `self` on target `device`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_parameter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameter</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">new_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">new_densities</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span><span class="p">)</span> \
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameter</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weight</span><span class="p">,</span> <span class="n">new_densities</span><span class="p">,</span>
                          <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Methods for batch dimension manipulations. </span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Message.batch_permute"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.batch_permute">[docs]</a>    <span class="k">def</span> <span class="nf">batch_permute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target_dims</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a permuted message whose tensor contents that include batch dimensions (e.g. parameters and particle</span>
<span class="sd">        values) are permuted w.r.t. `target_dims`.</span>

<span class="sd">        The dimensions specified in `target_dims` are relative to the batch dimensions only. Its values should be in</span>
<span class="sd">        range ``[-len(batch_shape), len(batch_shape) - 1]``</span>

<span class="sd">        `contiguous() &lt;https://pytorch.org/docs/stable/tensors.html?highlight=contiguous#torch.Tensor.contiguous&gt;`_</span>
<span class="sd">        will be called so that the returning message&#39;s tensor contents are contiguous</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        target_dims : list of ints</span>
<span class="sd">            The desired ordering of the target batch dimensions. Must have the same length as the message&#39;s batch shape.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            The permuted message from `self`.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        This method is a mimic of</span>
<span class="sd">        `torch.Tensor.permute() &lt;https://pytorch.org/docs/stable/tensors.html#torch.Tensor.permute&gt;`_.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target_dims</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">target_dims</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_dims</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="ow">and</span> \
            <span class="nb">all</span><span class="p">(</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">target_dims</span><span class="p">)</span>

        <span class="c1"># Translate negative dims to non-negative value</span>
        <span class="n">pos_target_dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">target_dims</span><span class="p">)</span> <span class="o">+</span> <span class="n">i</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">target_dims</span><span class="p">)</span>
        <span class="c1"># Permuted batch shape</span>
        <span class="n">new_b_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">pos_target_dims</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">))))</span>
        <span class="c1"># Permute order for batch and parameter dimensions together</span>
        <span class="n">b_p_dims</span> <span class="o">=</span> <span class="n">pos_target_dims</span> <span class="o">+</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)]</span>
        <span class="c1"># Permute order for sample and batch dimensions together.</span>
        <span class="n">b_s_dims</span> <span class="o">=</span> <span class="n">pos_target_dims</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">)))</span>

        <span class="n">new_parameter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">new_log_densities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="n">new_parameter</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">b_p_dims</span><span class="p">)</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="n">new_parameter</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weight has shape (b_shape + s_shape)</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">new_weight</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">b_s_dims</span><span class="p">)</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">new_weight</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameter</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weight</span><span class="p">,</span> <span class="n">new_log_densities</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_unsqueeze"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.batch_unsqueeze">[docs]</a>    <span class="k">def</span> <span class="nf">batch_unsqueeze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a new message with a dimension of size one inserted at the target batch dimension specified by `dim`.</span>

<span class="sd">        The target dimension is relative to the batch dimensions only. It should be in range</span>
<span class="sd">        ``[-len(batch_shape) - 1, len(batch_shape) + 1]``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dim : int</span>
<span class="sd">            The position where the new singleton dimension (a dim of size 1) is to be inserted.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            The unsqueezed message from `self`.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        This method is a mimic of</span>
<span class="sd">        `torch.unsqueeze() &lt;https://pytorch.org/docs/stable/torch.html?highlight=unsqueeze#torch.unsqueeze&gt;`_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">&lt;=</span> <span class="n">dim</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># Translate dim to positive value if it is negative</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="c1"># Get new batch shape</span>
        <span class="n">new_b_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">:]</span>

        <span class="n">new_parameter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">new_log_densities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (b_shape + s_shape)</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameter</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weight</span><span class="p">,</span> <span class="n">new_log_densities</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_index_select"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.batch_index_select">[docs]</a>    <span class="k">def</span> <span class="nf">batch_index_select</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a message that is a concatenation of the slices from `self` along the `dim` batch dimension and</span>
<span class="sd">        indexed by `index`.</span>

<span class="sd">        In other words, along `dim` dimension, the ``i`` th slice of the returned message is the ``index[i]`` th slice</span>
<span class="sd">        of `self`. Consequently, the size of the `dim` dimension of the returned message equals the length of `index`</span>
<span class="sd">        array.</span>

<span class="sd">        A `dim` value within the range ``[-len(batch_shape), len(batch_shape) - 1]`` can be used. Note that `dim` is</span>
<span class="sd">        relative to the batch dimension only.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dim : int</span>
<span class="sd">            The dimension along which entries will be selected according to `index`.</span>
<span class="sd">        index : torch.LongTensor</span>
<span class="sd">            The array of indices of entries along `dim` to be selected. Entries must be non-negative.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            The returned index-selected and concatenated message from `self`.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        This method is a mimic of</span>
<span class="sd">        `torch.index_select() &lt;https://pytorch.org/docs/stable/torch.html?highlight=index_select#torch.index_select&gt;`_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">dim</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">index</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span>

        <span class="c1"># Translate dim to positive value if it is negative</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">dim</span>
        <span class="c1"># Get new batch shape</span>
        <span class="n">new_b_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="n">index</span><span class="o">.</span><span class="n">shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span>

        <span class="n">new_parameter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">new_log_densities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (b_shape + s_shape)</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameter</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weight</span><span class="p">,</span> <span class="n">new_log_densities</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_index_put"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.batch_index_put">[docs]</a>    <span class="k">def</span> <span class="nf">batch_index_put</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a message whose entries along the dimension `dim` are slices from self message and are put into</span>
<span class="sd">        the positions along the axis specified by indices in `index`.</span>

<span class="sd">        In other words, along `dim` dimension, the ``index[i]`` th slice of the returned message is the ``i`` th slice</span>
<span class="sd">        of `self`. Consequently, the size of the `dim` dimension of the returned message equals the maximum value in the</span>
<span class="sd">        `index` array.</span>

<span class="sd">        For slices in the new message not referenced by `index`, they will be filled with identity values. For parameter</span>
<span class="sd">        tensor, the identity value is 0, and for particle weight tensor, the identity value is a positive uniform</span>
<span class="sd">        constant such that the sum across the sample dimensions is 1.</span>

<span class="sd">        A `dim` value within the range ``[-len(batch_shape), len(batch_shape) - 1]`` can be used. Note that `dim` is</span>
<span class="sd">        relative to the batch dimension only.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dim : int</span>
<span class="sd">            The dimension along which entries will be put according to `index`.</span>
<span class="sd">        index : torch.LongTensor</span>
<span class="sd">            The array of indices of entries along `dim` to be put. Entries must be non-negative.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            The returned index-put message of `self`.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        batch_index_select() :</span>
<span class="sd">            The inverse of batch_index_put(). There is no direct counterpart to this method in PyTorch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">dim</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">index</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">index</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Translate dim value to positive if it&#39;s negative</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">dim</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">dim</span>
        <span class="c1"># Get new batch shape. The size of dimension dim is determined by the maximum value in index</span>
        <span class="n">new_b_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span>

        <span class="n">new_parameter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">new_log_densities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span>

        <span class="c1"># To access tensor slice more easily, we swap the target dim with first dim, perform slicing and assignment on</span>
        <span class="c1">#   this new first dim, and swap it back</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="c1"># Identity value tensor</span>
            <span class="n">to_fill</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">new_b_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="c1"># Transpose target dimension with the first dimension</span>
            <span class="n">to_fill</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">to_fill</span><span class="p">,</span> <span class="n">dim0</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
            <span class="n">t_param</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">dim0</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
            <span class="c1"># Slice and assign</span>
            <span class="n">to_fill</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">t_param</span>
            <span class="c1"># Transpose back to get result</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">to_fill</span><span class="p">,</span> <span class="n">dim0</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (b_shape + s_shape)</span>
            <span class="c1"># Identity value tensor. Use ones here because we assume Message constructor will take care of normalization</span>
            <span class="n">to_fill</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">new_b_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="c1"># Transpose target dimension with the first dimension</span>
            <span class="n">to_fill</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">to_fill</span><span class="p">,</span> <span class="n">dim0</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
            <span class="n">t_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">dim0</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
            <span class="c1"># Slice and assign</span>
            <span class="n">to_fill</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">t_weight</span>
            <span class="c1"># Transpose back to get result</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">to_fill</span><span class="p">,</span> <span class="n">dim0</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameter</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weight</span><span class="p">,</span> <span class="n">new_log_densities</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_diagonal"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.batch_diagonal">[docs]</a>    <span class="k">def</span> <span class="nf">batch_diagonal</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a partial view of self with the its diagonal elements with respect to `dim1` and `dim2` appended as</span>
<span class="sd">        a dimension at the end of the shape.</span>

<span class="sd">        dim values in the range ``[-len(batch_shape), len(batch_shape) - 1]`` can be used. Note that `dim1` and `dim2`</span>
<span class="sd">        are relative to the batch dimensions only. The appended dimension will be placed as the last batch dimension,</span>
<span class="sd">        but before any sample or param dimensions.</span>

<span class="sd">        `contiguous() &lt;https://pytorch.org/docs/stable/tensors.html?highlight=contiguous#torch.Tensor.contiguous&gt;`_</span>
<span class="sd">        will be called so that the returning content tensors are contiguous.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dim1 : int, optional</span>
<span class="sd">            The first dimension of the 2D subspace where diagonal entries will be taken. Defaults to 0, the first batch</span>
<span class="sd">            dimension.</span>
<span class="sd">        dim2 : int, optional</span>
<span class="sd">            The second dimension of the 2D subspace where diagonal entries will be taken. Defaults to 1, the second</span>
<span class="sd">            batch dimension.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            The diagonalized message of `self`.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        This method is a mimic of</span>
<span class="sd">        `torch.diagonal() &lt;https://pytorch.org/docs/stable/torch.html?highlight=diagonal#torch.diagonal&gt;`_</span>
<span class="sd">        , with `offset` defaults to 0</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim1</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">dim1</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim2</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">dim2</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

        <span class="c1"># Translate dim value to positive if it&#39;s negative</span>
        <span class="n">dim1</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">dim1</span> <span class="k">if</span> <span class="n">dim1</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">dim1</span>
        <span class="n">dim2</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">dim2</span> <span class="k">if</span> <span class="n">dim2</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">dim2</span>
        <span class="c1"># Get new batch shape. The size of the appended diagonalized dimension should be the min of dim1 and dim2</span>
        <span class="n">new_b_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[:</span><span class="nb">min</span><span class="p">(</span><span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">)]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span> <span class="nb">max</span><span class="p">(</span><span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">)]</span> <span class="o">+</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="nb">max</span><span class="p">(</span><span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim2</span><span class="p">])])</span>

        <span class="n">new_parameter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">new_log_densities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="n">dim2</span><span class="p">)</span>
            <span class="c1"># Swap param dimension and appended diagonal batch dimension</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">dim0</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="n">new_parameter</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (b_shape + s_shape)</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="n">dim2</span><span class="p">)</span>
            <span class="c1"># Permute the appended diagonal batch dimension to the end of the existing batch dimensions</span>
            <span class="n">perm_order</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)))</span> <span class="o">+</span> <span class="p">[</span><span class="n">new_weight</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> \
                <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">)))</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">new_weight</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">perm_order</span><span class="p">)</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">new_weight</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameter</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weight</span><span class="p">,</span> <span class="n">new_log_densities</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_diag_embed"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.batch_diag_embed">[docs]</a>    <span class="k">def</span> <span class="nf">batch_diag_embed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">diag_dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">target_dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">target_dim2</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a message whose diagonals of certain 2D planes (dimensions specified by `target_dim1` and</span>
<span class="sd">        `target_dim2`) are filled by slices of self along the dimension specified by `diag_dim`).</span>

<span class="sd">        The last dimension of self is chosen by default as the diagonal entries to be filled, and the last two</span>
<span class="sd">        dimensions of the new message are chosen by default as the 2D planes where the diagonal entries will be filled</span>
<span class="sd">        in.</span>

<span class="sd">        The 2D planes will be shaped as square matrices, with the size of each dimension matches the size of the</span>
<span class="sd">        `diag_dim` dimension in self.</span>

<span class="sd">        The length of returned message&#39;s batch shape will be the length of original message&#39;s batch shape plus 1.</span>

<span class="sd">        For slots not on the diagonals of the resulting message, they will be filled with identity values. For parameter</span>
<span class="sd">        tensor, the identity value is 0, and for particle weight tensor, the identity value is a positive uniform</span>
<span class="sd">        constant such that the sum across the sample dimensions is 1.</span>

<span class="sd">        `contiguous() &lt;https://pytorch.org/docs/stable/tensors.html?highlight=contiguous#torch.Tensor.contiguous&gt;`_</span>
<span class="sd">        will be called so that the returning content tensors are contiguous.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        diag_dim : int, optional</span>
<span class="sd">            The dimension of `self` along which slices will be selected. Defaults to -1.</span>
<span class="sd">        target_dim1 : int, optional</span>
<span class="sd">            The first dimension of the target 2D planes in the target message. Defaults to -2.</span>
<span class="sd">        target_dim2 : int, optional</span>
<span class="sd">            The second dimension of the target 2D planes in the target message. Defaults to -1.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            The diagonally embedded message from `self`.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        This method is a mimic of</span>
<span class="sd">        `torch.diag_embed() &lt;https://pytorch.org/docs/stable/torch.html?highlight=diag_embed#torch.diag_embed&gt;`_</span>
<span class="sd">        , with `offset` default to 0 plus an additional diag_dim argument.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">diag_dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">diag_dim</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target_dim1</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">&lt;=</span> <span class="n">target_dim1</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target_dim2</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">&lt;=</span> <span class="n">target_dim2</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span>

        <span class="c1"># Translate dim value to positive if it&#39;s negative</span>
        <span class="n">diag_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">diag_dim</span> <span class="k">if</span> <span class="n">diag_dim</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">diag_dim</span>
        <span class="n">target_dim1</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">target_dim1</span> <span class="k">if</span> <span class="n">target_dim1</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">target_dim1</span>
        <span class="n">target_dim2</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">target_dim2</span> <span class="k">if</span> <span class="n">target_dim2</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">target_dim2</span>
        <span class="c1"># Get new batch shape. The size of target_dim1 and target_dim2 is determined by the size of diag_dim</span>
        <span class="n">diag_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">diag_dim</span><span class="p">]</span>
        <span class="n">other_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[:</span><span class="n">diag_dim</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">diag_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:])</span>
        <span class="n">first_new_dim</span><span class="p">,</span> <span class="n">second_new_dim</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">target_dim1</span><span class="p">,</span> <span class="n">target_dim2</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">target_dim1</span><span class="p">,</span> <span class="n">target_dim2</span><span class="p">)</span>
        <span class="n">other_shape</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">first_new_dim</span><span class="p">,</span> <span class="n">diag_size</span><span class="p">)</span>
        <span class="n">other_shape</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">second_new_dim</span><span class="p">,</span> <span class="n">diag_size</span><span class="p">)</span>
        <span class="n">new_b_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="n">other_shape</span><span class="p">)</span>

        <span class="n">new_parameter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">new_log_densities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span>

        <span class="c1"># Tensors fist need to have the diagonal entries dimension (diag_dim) permuted to the last dimension so that it</span>
        <span class="c1">#   will be picked up by torch.diag_embed()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">perm_order</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">)))</span>
            <span class="n">perm_order</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">diag_dim</span><span class="p">)</span>
            <span class="n">perm_order</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">diag_dim</span><span class="p">)</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="n">new_parameter</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">perm_order</span><span class="p">)</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag_embed</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="n">target_dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="n">target_dim2</span><span class="p">)</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="n">new_parameter</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (b_shape + s_shape)</span>
            <span class="c1"># For weights, the default entries to be filled in places other than the diagonal should be 1&#39;s, so we</span>
            <span class="c1">#   will first fill the log of input into the diagonal and then take exponential. 0&#39;s filled by</span>
            <span class="c1">#   torch.diag_embed() will be transformed to 1. Note that for these uniform entries the weights will be</span>
            <span class="c1">#   normalized across sample dimension during initialization so no worries.</span>
            <span class="n">log_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">new_weight</span><span class="p">)</span>
            <span class="n">perm_order</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">)))</span>
            <span class="n">perm_order</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">diag_dim</span><span class="p">)</span>
            <span class="n">perm_order</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">diag_dim</span><span class="p">)</span>
            <span class="n">log_weight</span> <span class="o">=</span> <span class="n">log_weight</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">perm_order</span><span class="p">)</span>
            <span class="n">log_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag_embed</span><span class="p">(</span><span class="n">log_weight</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="n">target_dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="n">target_dim1</span><span class="p">)</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">target_dim1</span><span class="p">)</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">new_weight</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameter</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weight</span><span class="p">,</span> <span class="n">new_log_densities</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_narrow"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.batch_narrow">[docs]</a>    <span class="k">def</span> <span class="nf">batch_narrow</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">length</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a message that is a narrowed version of `self` along the dimension specified by `dim`.</span>

<span class="sd">        Effectively, this method selects the chunk spanning ``[:length]`` along the dimension `dim` of `self`. The</span>
<span class="sd">        returned message and `self` share the same underlying storage.</span>

<span class="sd">        `contiguous() &lt;https://pytorch.org/docs/stable/tensors.html?highlight=contiguous#torch.Tensor.contiguous&gt;`_</span>
<span class="sd">        will be called so that the returning content tensors are contiguous.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dim : int</span>
<span class="sd">            The dimension of along which `self` will be narrowed.</span>
<span class="sd">        length : int</span>
<span class="sd">            The length of the message chunk to select. It must be no greater than the size of the `dim` dimension in</span>
<span class="sd">            `self`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            A narrowed message of `self`.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        This method is a mimic of</span>
<span class="sd">        `torch.narrow() &lt;https://pytorch.org/docs/stable/torch.html?highlight=narrow#torch.narrow&gt;`_</span>
<span class="sd">        , with `start` default to 0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">dim</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">length</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">length</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>

        <span class="c1"># Translate dim value to positive if it&#39;s negative</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">dim</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">dim</span>
        <span class="c1"># Get new batch shape.</span>
        <span class="n">new_b_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">length</span><span class="p">])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span>

        <span class="n">new_parameter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">new_log_densities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">narrow</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="n">length</span><span class="p">)</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="n">new_parameter</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (b_shape + s_shape)</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">narrow</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="n">length</span><span class="p">)</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">new_weight</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameter</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weight</span><span class="p">,</span> <span class="n">new_log_densities</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_broaden"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.batch_broaden">[docs]</a>    <span class="k">def</span> <span class="nf">batch_broaden</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">length</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a message that is a broadened version of `self` along the dimension specified by `dim`, with identity</span>
<span class="sd">        values filled in ``[dim_size + 1: length]`` along the dimension `dim` in the returned message.</span>

<span class="sd">        In other words, this method is concatenating an identity message to `self` along dimension `dim` so that the</span>
<span class="sd">        resulting dimension size is `length`.</span>

<span class="sd">        For parameter tensor, the identity value is 0, and for particle weight tensor, the identity value is a positive</span>
<span class="sd">        uniform constant such that the sum across the sample dimensions is 1.</span>

<span class="sd">        `contiguous() &lt;https://pytorch.org/docs/stable/tensors.html?highlight=contiguous#torch.Tensor.contiguous&gt;`_</span>
<span class="sd">        will be called so that the returning content tensors are contiguous.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dim : int</span>
<span class="sd">            The dimension of `self` which will be broadened in the returned message.</span>
<span class="sd">        length : int</span>
<span class="sd">            The length of the broadened dimension of the returned message. It must be greater than the size of the `dim`</span>
<span class="sd">            dimension in `self`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            A broadened message of `self`.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        batch_narrow() :</span>
<span class="sd">            The inverse of batch_broaden(). There is no direct counterpart to this method in PyTorch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">dim</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">length</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">length</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>

        <span class="c1"># Translate dim value to positive if it&#39;s negative</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">dim</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">dim</span>
        <span class="c1"># Get new batch shape.</span>
        <span class="n">new_b_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">length</span><span class="p">])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span>

        <span class="n">new_parameter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">new_log_densities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">to_concat_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">length</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]])</span> <span class="o">+</span> \
                              <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span>
            <span class="n">to_concat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">to_concat_shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">to_concat</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="n">new_parameter</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (b_shape + s_shape)</span>
            <span class="n">to_concat_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">length</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]])</span> <span class="o">+</span> \
                              <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span>
            <span class="n">to_concat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">to_concat_shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">to_concat</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">new_weight</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameter</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weight</span><span class="p">,</span> <span class="n">new_log_densities</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_summarize"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.batch_summarize">[docs]</a>    <span class="k">def</span> <span class="nf">batch_summarize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Implements the default Sum-Product summarization semantics. Summarizes over the batch dimension specified by</span>
<span class="sd">        `dim`. Returns a message with one less dimension.</span>

<span class="sd">        For Parameter message, the summarization is realized by taking the mean of the parameter tensor along dimension</span>
<span class="sd">        `dim`. For particles message, this is realized by taking addition defined for particle weights along dimension</span>
<span class="sd">        `dim`, a.k.a. factor product.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dim : int</span>
<span class="sd">            The dimension of `self` to be summarized over.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            The summarized message from `self`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">dim</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

        <span class="c1"># Translate dim value to positive if it&#39;s negative</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">dim</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">dim</span>
        <span class="c1"># Get new batch shape.</span>
        <span class="n">new_b_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span>

        <span class="n">new_parameter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">new_log_densities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (b_shape + s_shape)</span>
            <span class="c1"># For weights, since factor product is taken, we first convert weight values to log scale, perform summation</span>
            <span class="c1">#   across the batch dimension, then convert back to exponential scale.</span>
            <span class="c1"># The normalization of resulting weights will be taken care of by message initialization</span>
            <span class="n">log_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">new_weight</span><span class="p">)</span>
            <span class="n">log_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_weight</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_weight</span><span class="p">)</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameter</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weight</span><span class="p">,</span> <span class="n">new_log_densities</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_flatten"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.batch_flatten">[docs]</a>    <span class="k">def</span> <span class="nf">batch_flatten</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Flattens the set of batch dimensions specified by `dims` and append the flattened dimension as the last</span>
<span class="sd">        batch dimension. If `dims` is ``None``, will flatten all batch dimensions.</span>

<span class="sd">        `contiguous() &lt;https://pytorch.org/docs/stable/tensors.html?highlight=contiguous#torch.Tensor.contiguous&gt;`_</span>
<span class="sd">        will be called so that the returning content tensors are contiguous.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dims : iterable of ints, optional</span>
<span class="sd">            The set of batch dimensions to be flattened. Defaults to ``None``.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            The flattened message of `self`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">dims</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">dims</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span>
                                <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">dim</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">dims</span><span class="p">))</span>

        <span class="c1"># Translate dim value to positive if it&#39;s negative</span>
        <span class="n">dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">dim</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">dim</span> <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">dims</span><span class="p">)</span> <span class="k">if</span> <span class="n">dims</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> \
            <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)))</span>
        <span class="n">other_dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">))</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">dims</span><span class="p">)</span>
        <span class="c1"># Get new batch shape.</span>
        <span class="n">new_b_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">other_dims</span><span class="p">))</span> <span class="o">+</span> \
            <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)[</span><span class="n">dims</span><span class="p">])])</span>

        <span class="n">new_parameter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">new_log_densities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">perm_order</span> <span class="o">=</span> <span class="n">other_dims</span> <span class="o">+</span> <span class="n">dims</span> <span class="o">+</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)]</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="n">new_parameter</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">perm_order</span><span class="p">)</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">start_dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">other_dims</span><span class="p">),</span> <span class="n">end_dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="n">new_parameter</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (b_shape + s_shape)</span>
            <span class="n">perm_order</span> <span class="o">=</span> <span class="n">other_dims</span> <span class="o">+</span> <span class="n">dims</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">)))</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">new_weight</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">perm_order</span><span class="p">)</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">start_dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">other_dims</span><span class="p">),</span> <span class="n">end_dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">new_weight</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameter</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weight</span><span class="p">,</span> <span class="n">new_log_densities</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_reshape"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.batch_reshape">[docs]</a>    <span class="k">def</span> <span class="nf">batch_reshape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_batch_shape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a message with the same underlying data as self, but with the specified `new_batch_shape`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        new_batch_shape : iterable of int, or torch.Size</span>
<span class="sd">            The target batch shape.</span>

<span class="sd">        Returns</span>
<span class="sd">        --------</span>
<span class="sd">        Message</span>
<span class="sd">            A reshaped message from `self` with new batch shape.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        This method is a mimic of</span>
<span class="sd">        `torch.reshape() &lt;https://pytorch.org/docs/stable/torch.html?highlight=reshape#torch.reshape&gt;`_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span> <span class="ow">or</span> \
            <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">new_batch_shape</span><span class="p">))</span>

        <span class="n">new_batch_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">))</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span> <span class="k">else</span> \
            <span class="n">new_batch_shape</span>

        <span class="n">new_parameter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">new_log_densities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">new_batch_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (b_shape + s_shape)</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">new_batch_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">)</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_batch_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameter</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weight</span><span class="p">,</span> <span class="n">new_log_densities</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_expand"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.batch_expand">[docs]</a>    <span class="k">def</span> <span class="nf">batch_expand</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_batch_shape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a new view of `self` with singleton batch dimensions expanded to a larger size.</span>

<span class="sd">        Passing a -1 as the size for a batch dimension means not changing the size of that batch dimension.</span>

<span class="sd">        Expanding `self` would not allocate new memory for `self`&#39;s tensor contents, but would create a new view on the</span>
<span class="sd">        existing tensors. Any dimension of size 1 can be expanded to an arbitrary value without allocating new memory.</span>

<span class="sd">        Note that `new_batch_shape` is relative to the batch dimensions only.</span>

<span class="sd">        `contiguous() &lt;https://pytorch.org/docs/stable/tensors.html?highlight=contiguous#torch.Tensor.contiguous&gt;`_</span>
<span class="sd">        will be called so that the returning content tensors are contiguous.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        new_batch_shape : iterable of int, or torch.Size</span>
<span class="sd">            The target expanded batch shape. Must have the same length as `self`&#39;s current batch shape.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            An expanded message from `self`.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        This method is a mimic of</span>
<span class="sd">        `torch.Tensor.expand() &lt;https://pytorch.org/docs/stable/tensors.html?highlight=expand#torch.Tensor.expand&gt;`_.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span> <span class="ow">or</span> \
            <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">new_batch_shape</span><span class="p">))</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">))</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span>

        <span class="n">new_batch_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">))</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span> <span class="k">else</span> \
            <span class="n">new_batch_shape</span>

        <span class="n">new_parameter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">new_log_densities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">new_shape</span> <span class="o">=</span> <span class="n">new_batch_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span>
            <span class="n">new_parameter</span> <span class="o">=</span> <span class="n">new_parameter</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">new_shape</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (b_shape + s_shape)</span>
            <span class="n">new_shape</span> <span class="o">=</span> <span class="n">new_batch_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">new_weight</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">new_shape</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_batch_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameter</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weight</span><span class="p">,</span> <span class="n">new_log_densities</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Methods for Operations on Message Events </span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="Message.event_transform"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.event_transform">[docs]</a>    <span class="k">def</span> <span class="nf">event_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trans</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Applies a transformation on the `self`&#39;s event values. Returns the transformed message.</span>

<span class="sd">        `self` contents will be cloned before being passed to the transformed message.</span>

<span class="sd">        For now, only Particles message support transformations. `reduce_type()` will first be called to eliminate the</span>
<span class="sd">        parameter components before performing the transformation.</span>

<span class="sd">        The adjustment made to the particle values and log sampling densities:</span>

<span class="sd">        * Apply the transformation directly on the particle tensors in ``self.particles``.</span>
<span class="sd">        * Log sampling density tensors in ``self.log_densities`` will be adjusted by adding the log absolute determinant</span>
<span class="sd">          of the Jacobian of the transformation::</span>

<span class="sd">             log P(Y) = log P(X) + log |det (dX / dY)|</span>

<span class="sd">        * Weights are kept the same, but the tensor will be cloned.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        trans : torch.distributions.transforms.Transform</span>
<span class="sd">            The transformation object</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            The transformed message.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        AssertionError</span>
<span class="sd">            If `dist_info` attribute is not present in ``self.attr``</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        `torch.distributions.Transform &lt;https://pytorch.org/docs/stable/distributions.html#torch.distributions.transforms.Transform&gt;`_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">trans</span><span class="p">,</span> <span class="n">Transform</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span>

        <span class="c1"># First clone and reduce</span>
        <span class="n">cloned_msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduce_type</span><span class="p">(</span><span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span><span class="p">)</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="n">cloned_msg</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_log_densities</span> <span class="o">=</span> <span class="n">cloned_msg</span><span class="o">.</span><span class="n">log_densities</span>

        <span class="n">new_particles</span> <span class="o">=</span> <span class="n">trans</span><span class="p">(</span><span class="n">new_particles</span><span class="p">)</span>
        <span class="n">new_log_densities</span> <span class="o">+=</span> <span class="n">trans</span><span class="o">.</span><span class="n">log_abs_det_jacobian</span><span class="p">(</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">particles</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">)</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="n">batch_shape</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span>
                          <span class="n">sample_shape</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">event_shape</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">particles</span><span class="o">=</span><span class="n">new_particles</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span>
                          <span class="n">log_densities</span><span class="o">=</span><span class="n">new_log_densities</span><span class="p">,</span> <span class="o">**</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.event_reweight"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.event_reweight">[docs]</a>    <span class="k">def</span> <span class="nf">event_reweight</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target_log_prob</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a new message with the same type of `self` with the same particle values and log sampling densities</span>
<span class="sd">        as `self`, but a different weight tensor, derived from importance weighting `target_log_pdf` against stored</span>
<span class="sd">        log sampling density tensors in ``self.log_densities``.</span>

<span class="sd">        `self` &#39;s type must be either ``MessageType.Particles`` or ``MessageType.Both`` to support this method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        target_log_prob : torch.Tensor</span>
<span class="sd">            The batched log pdf of the `self` particles w.r.t. to the batched target distributions the new message is</span>
<span class="sd">            to encode. Should have shape ``(self.b_shape + self.s_shape)``.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            A new importance-reweighted message with the same type and components as `self` except the importance</span>
<span class="sd">            weight.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        AssertionError</span>
<span class="sd">            If `self` has neither type `MessageType.Particles`` nor type ``MessageType.Both``.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        The importance weighting procedure can be summarized in two steps::</span>

<span class="sd">            log_ratio = target_log_pdf - joint_log_density</span>
<span class="sd">            new_weight = normalize(exp(log_ratio))</span>

<span class="sd">        Some remarks:</span>

<span class="sd">        * ``joint_log_density`` here refers to the joint log sampling density of the combinatorially concatenated</span>
<span class="sd">          marginal event particles in ``self.particles``. Therefore, if there are multiple random variables, this</span>
<span class="sd">          quantity is derived by first expanding each marginal log sampling density tensor in ``self.log_densities``</span>
<span class="sd">          to the full sampling dimensions, then taking the sum over all such expanded log density tensor.</span>
<span class="sd">        * The last step guarantees that ``new_weight`` sums to 1 across sampling dimensions. Note that this step is not</span>
<span class="sd">          explicitly implemented in this method; we assume it is taken care of by Message class constructor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target_log_prob</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">target_log_prob</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span>

        <span class="c1"># Obtain joint sampling density. Should have shape (self.s_shape)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">joint_density</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">exp_den</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span><span class="p">):</span>
                <span class="n">dims</span> <span class="o">=</span> <span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
                <span class="n">dims</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">exp_den</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">dims</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">))</span>
            <span class="n">joint_density</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">exp_den</span><span class="p">)</span>

        <span class="c1"># Make joint_density broadcastable by prepending batch dimensions</span>
        <span class="n">dims</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">)</span>
        <span class="n">joint_density</span> <span class="o">=</span> <span class="n">joint_density</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">dims</span><span class="p">)</span>
        <span class="n">new_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">target_log_prob</span> <span class="o">-</span> <span class="n">joint_density</span><span class="p">)</span>    <span class="c1"># Unweighted</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="n">batch_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">param_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span>
                          <span class="n">sample_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">event_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">parameter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parameter</span><span class="p">,</span>
                          <span class="n">particles</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">log_densities</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span><span class="p">,</span>
                          <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.event_marginalize"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.event_marginalize">[docs]</a>    <span class="k">def</span> <span class="nf">event_marginalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">event_dim</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a message from `self` where the event dimension specified bv `event_dim` is marginalized,</span>
<span class="sd">        corresponding to marginalizing the corresponding random variable.</span>

<span class="sd">        Only messages with particles support this operation. If `self`&#39;s message type is ``MessageType.Both``, a</span>
<span class="sd">        ``MessageType.Parameter`` type message will be returned, where the parameter of `self` is discarded.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        event_dim : int</span>
<span class="sd">            Which event dimension / random variable to be marginalized over. Can accept a value in the range</span>
<span class="sd">            ``[-len(event_shape), len(event_shape) - 1]``.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            A ``MessageType.Particles`` type message where the `event_dim` th event dimension is marginalized over.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        AssertionError</span>
<span class="sd">            If `self` does not contain particles.</span>
<span class="sd">        AssertionError</span>
<span class="sd">            If `self`&#39;s ``len(event_shape)`` is 1, i.e., currently only one event dimension, but still this method is</span>
<span class="sd">            called to marginalize the only left event dimension.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Regarding the implementation:</span>

<span class="sd">        Marginalization of the particles is implemented by simply discarding the target particle value tensor as well as</span>
<span class="sd">        its corresponding log sampling density tensor, and summing over the target prob tensor over the event dimension.</span>
<span class="sd">        The target prob tensor is recovered by multiplying the weight tensor with the cross product of all of the</span>
<span class="sd">        marginal sampling density tensor.</span>

<span class="sd">        Note that the target prob tensor recovered in this way is **NOT** the</span>
<span class="sd">        actual probability w.r.t. the target distributions, but one that is proportional to that up to a normalization</span>
<span class="sd">        constant factor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">event_dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">event_dim</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> \
            <span class="s2">&quot;Only message with particles can be marginalized over. Marginalization over distribution parameter is not&quot;</span> \
            <span class="s2">&quot; well defined.&quot;</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">,</span> \
            <span class="s2">&quot;Attempting to marginalize over a message with one a single event dimension.&quot;</span>

        <span class="c1"># Convert event_dim to positive if it&#39;s negative</span>
        <span class="n">event_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">event_dim</span> <span class="k">if</span> <span class="n">event_dim</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">event_dim</span>

        <span class="c1"># Discard the target particle</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">[:</span><span class="n">event_dim</span><span class="p">])</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">[</span><span class="n">event_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]))</span>
        <span class="n">new_densities</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span><span class="p">[:</span><span class="n">event_dim</span><span class="p">])</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span><span class="p">[</span><span class="n">event_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]))</span>
        <span class="n">new_s_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">[:</span><span class="n">event_dim</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">[</span><span class="n">event_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span>
        <span class="n">new_e_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">[:</span><span class="n">event_dim</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">[</span><span class="n">event_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span>

        <span class="c1"># Recover target prob</span>
        <span class="c1"># First take cross product of all marginal sampling density</span>
        <span class="n">expand_log_den</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span><span class="p">):</span>
            <span class="n">view_dim</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">view_dim</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
            <span class="n">expand_log_den</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">view_dim</span><span class="p">))</span>

        <span class="c1"># Take joint sum and exponentialize, which is equivalent to cross product.</span>
        <span class="n">joint_density</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">expand_log_den</span><span class="p">))</span>
        <span class="c1"># Now expand dimensions even more to full batch dimensions. Resulting shape should be (b_shape + s_shape)</span>
        <span class="n">view_dim</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">)</span>
        <span class="n">joint_density</span> <span class="o">=</span> <span class="n">joint_density</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">view_dim</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">joint_density</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span>

        <span class="c1"># Recover target_prob, and sum over event_dim.</span>
        <span class="n">target_prob</span> <span class="o">=</span> <span class="n">joint_density</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">summed_prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">target_prob</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">event_dim</span><span class="p">)</span>

        <span class="c1"># Obtain new weight</span>
        <span class="n">mar_expand_log_den</span> <span class="o">=</span> <span class="n">expand_log_den</span><span class="p">[:</span><span class="n">event_dim</span><span class="p">]</span> <span class="o">+</span> <span class="n">expand_log_den</span><span class="p">[</span><span class="n">event_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span>
        <span class="n">mar_joint_density</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">mar_expand_log_den</span><span class="p">))</span>
        <span class="n">view_dim</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">new_s_shape</span><span class="p">)</span>
        <span class="n">mar_joint_density</span> <span class="o">=</span> <span class="n">mar_joint_density</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">view_dim</span><span class="p">)</span>
        <span class="n">new_weight</span> <span class="o">=</span> <span class="n">summed_prob</span> <span class="o">/</span> <span class="n">mar_joint_density</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span><span class="p">,</span>
                          <span class="n">batch_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">sample_shape</span><span class="o">=</span><span class="n">new_s_shape</span><span class="p">,</span> <span class="n">event_shape</span><span class="o">=</span><span class="n">new_e_shape</span><span class="p">,</span>
                          <span class="n">particles</span><span class="o">=</span><span class="n">new_particles</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">log_densities</span><span class="o">=</span><span class="n">new_densities</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.event_concatenate"><a class="viewcode-back" href="../../references/graphical/data-structures.html#pysigma.defs.Message.event_concatenate">[docs]</a>    <span class="k">def</span> <span class="nf">event_concatenate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cat_event_dims</span><span class="p">,</span> <span class="n">target_event_dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Concatenate the particle events corresponding to the event dimensions specified by `cat_event_dims`. The new</span>
<span class="sd">        concatenated events will be placed at `target_event_dim` dimension.</span>

<span class="sd">        To concatenate events means to</span>

<span class="sd">        1. combinatorially concatenate the particle value tensors,</span>
<span class="sd">        2. take the cross product of associated marginal sampling density tensors and flatten it,</span>
<span class="sd">        3. reshape the weight tensor into correct flattened shape.</span>

<span class="sd">        Note that the event dimensions will be concatenated in the order given by `cat_event_dims`.</span>

<span class="sd">        Only messages with particles support this operation. If `self`&#39;s message type is ``MessageType.Both``, a</span>
<span class="sd">        ``MessageType.Parameter`` type message will be returned, where the parameter of `self` is discarded.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        cat_event_dims : iterable of int</span>
<span class="sd">            The list of event dimensions to be concatenated. Must have length at least 2. Each should be in range</span>
<span class="sd">            ``[-len(event_shape), len(event_shape) - 1]``.</span>
<span class="sd">        target_event_dim : int</span>
<span class="sd">            The target event dimension where the concatenated event will be placed. Should be in range</span>
<span class="sd">            ``[-len(event_shape) + k, len(event_shape) - k - 1]``, where ``k`` equals to ``len(cat_event_dims)``.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            A ``Message.Particles`` type message where the specified event dimensions are concatenated.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        AssertionError</span>
<span class="sd">            If `self` does not contain particles.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cat_event_dims</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">)</span>
        <span class="n">cat_event_dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">cat_event_dims</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">cat_event_dims</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span>
                   <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">cat_event_dims</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">d</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">cat_event_dims</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
                   <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">cat_event_dims</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target_event_dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">target_event_dim</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> \
            <span class="s2">&quot;Only message with particles can concatenate event dimensions. Such operation on distribution parameter is &quot;</span> \
            <span class="s2">&quot;not well defined.&quot;</span>

        <span class="c1"># Convert dims to positive values if they are negative</span>
        <span class="n">cat_event_dims</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">d</span> <span class="k">if</span> <span class="n">d</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">cat_event_dims</span><span class="p">]</span>
        <span class="n">target_event_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">target_event_dim</span> <span class="k">if</span> <span class="n">target_event_dim</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">target_event_dim</span>

        <span class="c1"># Collect elements to be concatenated, in the order given by cat_event_dims. Also the pre-flattened shape</span>
        <span class="n">cat_particles</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">cat_event_dims</span><span class="p">)</span>
        <span class="n">cat_densities</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">cat_event_dims</span><span class="p">)</span>
        <span class="n">cat_s_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">cat_event_dims</span><span class="p">])</span>
        <span class="c1"># Collect the residues that are not to be concatenated</span>
        <span class="n">res_particles</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">))</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">cat_event_dims</span><span class="p">)</span>
        <span class="n">res_densities</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">))</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">cat_event_dims</span><span class="p">)</span>
        <span class="c1"># New shapes</span>
        <span class="n">new_s_shape</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">))</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">cat_event_dims</span><span class="p">]</span>
        <span class="n">new_s_shape</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">target_event_dim</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">cat_event_dims</span><span class="p">]))</span>
        <span class="n">new_e_shape</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">))</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">cat_event_dims</span><span class="p">]</span>
        <span class="n">new_e_shape</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">target_event_dim</span><span class="p">,</span> <span class="nb">sum</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">cat_event_dims</span><span class="p">]))</span>

        <span class="c1"># Combinatorially concatenate particle values. Flatten result and insert to the rest to form new particle tuple</span>
        <span class="n">comb_particles</span> <span class="o">=</span> <span class="n">KnowledgeServer</span><span class="o">.</span><span class="n">combinatorial_cat</span><span class="p">(</span><span class="n">cat_particles</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">comb_particles</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">cat_s_shape</span>
        <span class="n">flat_particles</span> <span class="o">=</span> <span class="n">comb_particles</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">comb_particles</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>        <span class="c1"># flatten</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="n">res_particles</span><span class="p">[:</span><span class="n">target_event_dim</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">flat_particles</span><span class="p">]</span> <span class="o">+</span> <span class="n">res_particles</span><span class="p">[</span><span class="n">target_event_dim</span><span class="p">:]</span>

        <span class="c1"># Take cross product of marginal sampling densities and flatten.</span>
        <span class="n">expand_log_den</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cat_densities</span><span class="p">):</span>
            <span class="n">view_dim</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cat_s_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">view_dim</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">cat_s_shape</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
            <span class="n">expand_log_den</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">view_dim</span><span class="p">))</span>
        <span class="n">joint_log_den</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">expand_log_den</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">joint_log_den</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">cat_s_shape</span>
        <span class="n">flat_log_den</span> <span class="o">=</span> <span class="n">joint_log_den</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>       <span class="c1"># flatten</span>
        <span class="n">new_densities</span> <span class="o">=</span> <span class="n">res_densities</span><span class="p">[:</span><span class="n">target_event_dim</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">flat_log_den</span><span class="p">]</span> <span class="o">+</span> <span class="n">res_densities</span><span class="p">[</span><span class="n">target_event_dim</span><span class="p">:]</span>

        <span class="c1"># Reshape weight tensor into correct flattened shape</span>
        <span class="c1"># First permute cat_event_dims to the last dimensions</span>
        <span class="n">new_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># of shape (b_shape + sample_shape)</span>
            <span class="n">b_cat_event_dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">cat_event_dims</span><span class="p">)</span>      <span class="c1"># Account for batch dims at front</span>
            <span class="n">b_target_event_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">target_event_dim</span>
            <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">b_cat_event_dims</span><span class="p">:</span>
                <span class="n">perm_order</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_weight</span><span class="o">.</span><span class="n">dim</span><span class="p">())</span> <span class="k">if</span> <span class="n">d</span> <span class="o">!=</span> <span class="n">dim</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">dim</span><span class="p">]</span>
                <span class="n">new_weight</span> <span class="o">=</span> <span class="n">new_weight</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">perm_order</span><span class="p">)</span>
            <span class="k">assert</span> <span class="n">new_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">cat_event_dims</span><span class="p">):]</span> <span class="o">==</span> <span class="n">cat_s_shape</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">new_weight</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">new_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">cat_event_dims</span><span class="p">)]</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">]))</span>     <span class="c1"># flatten</span>
            <span class="n">perm_order</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">new_weight</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">perm_order</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">b_target_event_dim</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">new_weight</span> <span class="o">=</span> <span class="n">new_weight</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">perm_order</span><span class="p">)</span>         <span class="c1"># Permute flattened dims to target_event_dim</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span><span class="p">,</span>
                          <span class="n">batch_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">sample_shape</span><span class="o">=</span><span class="n">new_s_shape</span><span class="p">,</span> <span class="n">event_shape</span><span class="o">=</span><span class="n">new_e_shape</span><span class="p">,</span>
                          <span class="n">particles</span><span class="o">=</span><span class="n">new_particles</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">new_weight</span><span class="p">,</span> <span class="n">log_densities</span><span class="o">=</span><span class="n">new_densities</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">new_msg</span></div></div>



<span class="c1"># TODO: Enum class of all the inference method</span>
<span class="k">class</span> <span class="nc">InferenceMethod</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="n">BP</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">PARTICLE_BP</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">VMP</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">PARTICLE_VMP</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">EP</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">PARTICLE_EP</span> <span class="o">=</span> <span class="mi">5</span>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Jincheng Zhou, Yunzhe Wang, Volkan Ustun, Paul Rosenbloom @ USC Institute for Creative Technologies

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>