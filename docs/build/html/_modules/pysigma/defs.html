

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pysigma.defs &mdash; PySigma 0.0.2 documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> PySigma
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Table of Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../introduction/intro.html">Introduction and Tutorials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../introduction/getting-started.html">Getting Started</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../references/index.html">References</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../references/cognitive/index.html">Cognitive</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../references/cognitive/predicate.html">Predicate</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../references/graphical/index.html">Graphical</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../references/graphical/message.html">Message</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../references/utils/index.html">Utils</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/index.html">Example Models</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">PySigma</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>pysigma.defs</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for pysigma.defs</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Basic structures in the graphical architecture</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="k">import</span> <span class="n">Transform</span>
<span class="kn">from</span> <span class="nn">torch.distributions.constraints</span> <span class="k">import</span> <span class="n">Constraint</span>
<span class="kn">from</span> <span class="nn">enum</span> <span class="k">import</span> <span class="n">Enum</span><span class="p">,</span> <span class="n">Flag</span><span class="p">,</span> <span class="n">auto</span>
<span class="kn">from</span> <span class="nn">collections.abc</span> <span class="k">import</span> <span class="n">Iterable</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="k">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="k">import</span> <span class="n">DistributionServer</span><span class="p">,</span> <span class="n">KnowledgeTranslator</span>


<span class="c1"># Variable Metatypes and Variable for general inference</span>
<span class="k">class</span> <span class="nc">VariableMetatype</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="n">Indexing</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Particle indexing variable, first dimension of a message</span>
    <span class="n">Relational</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Relational variable, second set of dimensions of a message</span>
    <span class="n">Random</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Random variable, last set of dimensions of a message</span>
    <span class="n">Parameter</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># Parameter variable, last dimensions of a distribution&#39;s parameter tensor</span>


<span class="k">class</span> <span class="nc">Variable</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Variable as in variable nodes in the graphical architecture. Store information about this variable such as</span>
<span class="sd">            its meta-type and dimension size</span>
<span class="sd">        The equality testing is used for matching variables in Alpha-Beta graphs. Two variables are equal if and only</span>
<span class="sd">            if ALL of the fields are equal.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">metatype</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">value_constraints</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Instantiate a variable. Optionally indicates a set of value constraints if and only if variable is Random</span>
<span class="sd">                metatype.</span>

<span class="sd">            :param name:                a str. The name of this variable</span>
<span class="sd">            :param metatype:            VariableMetatype. The metatype of this variable: Indexing, Relational, Random,</span>
<span class="sd">                                            or Parameter</span>
<span class="sd">            :param size:                an int. The size of the dimension this variable corresponds to</span>
<span class="sd">            :param value_constraints:   an Iterable of torch.distributions.constraints.Constraint instances. The set of</span>
<span class="sd">                                            value constraints that determine the value range (support) of this random</span>
<span class="sd">                                            variable. Should specify if and only if metatype is Random.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">metatype</span><span class="p">,</span> <span class="n">VariableMetatype</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">value_constraints</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">value_constraints</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">)</span> <span class="ow">and</span>
                                             <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">Constraint</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">value_constraints</span><span class="p">))</span>
        <span class="k">assert</span> <span class="p">(</span><span class="n">value_constraints</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="p">(</span><span class="n">metatype</span> <span class="ow">is</span> <span class="n">VariableMetatype</span><span class="o">.</span><span class="n">Random</span><span class="p">)</span>

        <span class="c1"># Variable name, its identity. Used for variable matching. Of type str</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="c1"># Variable meta-type, of type VariableMetatype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metatype</span> <span class="o">=</span> <span class="n">metatype</span>
        <span class="c1"># Variable size. Size of the dimension that the variable corresponds to. Of type int</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="c1"># List of value constraints if the Variable is of Random metatype.</span>
        <span class="c1">#   Useful at Beta-join to select globally valid particle values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">constraints</span> <span class="o">=</span> <span class="n">value_constraints</span>

    <span class="k">def</span> <span class="nf">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="c1"># override so &#39;==&#39; operator test variable equality</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Variable</span><span class="p">)</span>
        <span class="n">val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">name</span> <span class="ow">and</span> \
              <span class="bp">self</span><span class="o">.</span><span class="n">metatype</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">metatype</span> <span class="ow">and</span> \
              <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">size</span> <span class="ow">and</span> \
              <span class="bp">self</span><span class="o">.</span><span class="n">constraints</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">constraints</span>

        <span class="k">return</span> <span class="n">val</span>

    <span class="k">def</span> <span class="nf">__ne__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="c1"># override so &#39;!=&#39; operator test variable inequality</span>
        <span class="k">return</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__eq__</span><span class="p">(</span><span class="n">other</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># override to provide the name as the string representation</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span>

    <span class="k">def</span> <span class="nf">__hash__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># override so that hash value of the string representation of the variable is used</span>
        <span class="k">return</span> <span class="nb">hash</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metatype</span><span class="p">)</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">)</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">constraints</span><span class="p">))</span>


<span class="c1"># Generalized message type and message representation</span>
<span class="k">class</span> <span class="nc">MessageType</span><span class="p">(</span><span class="n">Flag</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Enum class to represent message types</span>

<span class="sd">        The True-valued boolean relationship between types, using the &#39;in&#39; operator:</span>
<span class="sd">            - Undefined in Undefined == Undefined in Parameter == Undefined in Particles == Undefined in Both == True</span>
<span class="sd">            - Parameter in Parameter == Undefined in Both == True</span>
<span class="sd">            - Particles in Particles == Undefined in Both == True</span>
<span class="sd">        All other relations are False.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Undefined</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">Parameter</span> <span class="o">=</span> <span class="n">auto</span><span class="p">()</span>
    <span class="n">Particles</span> <span class="o">=</span> <span class="n">auto</span><span class="p">()</span>
    <span class="n">Both</span> <span class="o">=</span> <span class="n">Parameter</span> <span class="o">|</span> <span class="n">Particles</span>


<div class="viewcode-block" id="Message"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message">[docs]</a><span class="k">class</span> <span class="nc">Message</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Message to be propagated between nodes in the graphical architecture.</span>

<span class="sd">    The `Message` class is the most fundamental data structure in PySigma that carries the knowledge of a batch of</span>
<span class="sd">    distributions to be processed by downstream graphs.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    msg_type : {``MessageType.Undefined``, ``MessageType.Parameter``, ``MessageType.Particles``, ``MessageType.Both``}</span>
<span class="sd">        The type of this message.</span>
<span class="sd">    batch_shape : torch.Size</span>
<span class="sd">        The size of the batch dimensions. Must be a shape of **at least** length 1.</span>
<span class="sd">    param_shape : torch.Size, optional</span>
<span class="sd">        The size of the parameter dimension of `parameter`. Must specify if `msg_type` is ``MessageType.Parameter``.</span>
<span class="sd">        Must be a shape of **exactly** length 1.</span>
<span class="sd">    sample_shape : torch.Size, optional</span>
<span class="sd">        The size of the sample dimensions of each particle tensor in `particles` respectively in order. Must specify if</span>
<span class="sd">        message type is ``MessageType.Particle``. Must be a shape of **at least** length 1.</span>
<span class="sd">    event_shape : torch.Size, optional</span>
<span class="sd">        The size of the event dimensions of each particle tensor in `particles` respectively in order. Must specify if</span>
<span class="sd">        message type is ``MessageType.Particle``. Must be a shape of **at least** length 1.</span>
<span class="sd">    parameter : torch.Tensor or an int of 0, optional</span>
<span class="sd">        The parameter tensor to the batch of distributions this message is encoding. Must specify if the message type is</span>
<span class="sd">        ``MessageType.Parameter``. A torch.Tensor of shape ``batch_shape + param_shape`` if the parameters do not</span>
<span class="sd">        represent the identity in the parameter vector space. Alternatively, can be an int of 0 to specify the identity.</span>
<span class="sd">        Default to an int of 0.</span>
<span class="sd">    particles : iterable of torch.Tensor, optional</span>
<span class="sd">        The list of particles representing events w.r.t. each random variable respectively whose collective joint</span>
<span class="sd">        distribution this message is encoding. Must specify if the message type is ``MessageType.Particles``. The jth</span>
<span class="sd">        entry of the iterable should have shape ``sample_shape[j] + event_shape[j]``.</span>
<span class="sd">    weights : torch.Tensor or an int of 1, optional</span>
<span class="sd">        The importance weight tensor that, when multiplied with the exponential of the cross product of the log sampling</span>
<span class="sd">        densities in `log_densities`, yields the pdf of each combined particle w.r.t. the target distribution that this</span>
<span class="sd">        message is encoding. Must specify if the message type is ``MessageType.Particles``. If the weights are</span>
<span class="sd">        non-uniform, must be a **positively valued** tensor of shape ``batch_shape + sample_shape``. The supplied tensor</span>
<span class="sd">        will be normalized during initialization so that it sums to 1 across the subspace spanned by the sample</span>
<span class="sd">        dimensions. Alternatively, can be an int of 1 to specify the uniform weight. Default to 1.</span>
<span class="sd">    log_densities : iterable of torch.Tensor, optional</span>
<span class="sd">        The jth entry in the iterable represents the log pdf of the jth particle in `particles` w.r.t. the (marginal)</span>
<span class="sd">        sampling distribution from which the jth particle was originally drawn. Must specify if the message type is</span>
<span class="sd">        ``MessageType.Particles``. The jth entry must have shape ``sample_shape[j]``.</span>
<span class="sd">    **kwargs</span>
<span class="sd">        Other keyword arguments that specify special attributes of the message. Will be deep copied when the message is</span>
<span class="sd">        cloned.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    type : {``MessageType.Undefined``, ``MessageType.Parameter``, ``MessageType.Particles``, ``MessageType.Both``}</span>
<span class="sd">        Message type.</span>
<span class="sd">    b_shape : torch.Size</span>
<span class="sd">        Batch shape.</span>
<span class="sd">    p_shape : torch.Size</span>
<span class="sd">        Parameter shape.</span>
<span class="sd">    s_shape : torch.Size</span>
<span class="sd">        Sample shape.</span>
<span class="sd">    e_shape : torch.Size</span>
<span class="sd">        Event shape.</span>
<span class="sd">    parameter : torch.Tensor or None</span>
<span class="sd">        Parameter tensor</span>
<span class="sd">    particles : list of torch.Tensor or None</span>
<span class="sd">        List of particle value tensors</span>
<span class="sd">    weight : torch.Tensor or None</span>
<span class="sd">        Particle weight tensor</span>
<span class="sd">    log_densities : list of torch.Tensor or None</span>
<span class="sd">        List of particles log sampling tensors</span>
<span class="sd">    attr : dict</span>
<span class="sd">        Miscellaneous optional attributes, specified by **kwargs in the constructor.</span>

<span class="sd">    Notes</span>
<span class="sd">    _____</span>
<span class="sd">    In PySigma Graphical Architecture, a message can represent not only a single joint distribution w.r.t. multiple</span>
<span class="sd">    random variables, but a *batch* of such joint distribution instances. The distribution instances in the batch are</span>
<span class="sd">    mutually independent, but may or may not be identically distributed. This batch is managed and indexed by the batch</span>
<span class="sd">    dimensions, specified by `batch_shape`.</span>

<span class="sd">    Depending on how each of the distribution instance is represented, a message can be roughly categorized into two</span>
<span class="sd">    types: *Parameter* type or *Particles* type.</span>

<span class="sd">    1. *Parameter* type: a message of this type encodes a batch of distributions by holding their parameter tensors. The</span>
<span class="sd">       semantics of the parameters depends on the context, e.g. whether they are natural parameters to exponential</span>
<span class="sd">       family distributions or conventional parameters to PyTorch distribution class. For the latter one, the semantics</span>
<span class="sd">       may even be distribution class dependent.</span>

<span class="sd">       Specifying the `parameter` argument only in the constructor is sufficient in terms of the message contents.</span>

<span class="sd">    2. *Particles* type: a message of this type encodes a batch of distributions by a particle list, with the particles</span>
<span class="sd">       being importantly weighted to correctly reflect their pdf w.r.t. to each of the target distribution in the</span>
<span class="sd">       distribution batch. In other words, conceptually, each entry in the particle list is a 3-tuple:</span>
<span class="sd">       ``(x, w_x, log_p(x))`` where ``x`` is the event value, ``log_p(x)`` is the log pdf of ``x`` w.r.t. its sampling</span>
<span class="sd">       distribution ``P(x)``, and ``w_x`` is defined as the ratio of ``Q(x)``, the target distribution pdf, over</span>
<span class="sd">       ``P(x)``. Therefore, the target pdf of ``x`` can be recovered by::</span>

<span class="sd">           Q(x) = w_x * exp(log_p(x))</span>
<span class="sd">           log Q(x) = log(w_X) + log_p(x)</span>

<span class="sd">       Note that a message uses a single list of particles to encode and approximate each and every distribution in the</span>
<span class="sd">       batch. In other words, the set of event values used to represent each distribution instance is the same, but the</span>
<span class="sd">       importance weights assigned to each event value by different distribution instances are different. This is the</span>
<span class="sd">       reason that `weight` tensor should include batch dimensions, whereas particle tensors in `particles` and log</span>
<span class="sd">       sampling density tensors in `log_densities` should not.</span>

<span class="sd">       When there are multiple random variables, each distribution instance in the batch is a joint distribution</span>
<span class="sd">       over all random variables. In this case, each of the entry in the provided `particles` are events w.r.t. each</span>
<span class="sd">       random variable *only*. To represent the joint distributions, a list of *joint* particles will be formed by</span>
<span class="sd">       concatenating the event tensors in `particles` combinatorially, or so to speak, by taking the tensor product.</span>
<span class="sd">       Accordingly, the log sampling density vectors in `log_densities` will be taken cross product to form a higher</span>
<span class="sd">       dimensional sampling density tensors. In this way, the joint particles are effectively arranged in a lattice in</span>
<span class="sd">       the joint event space, therefore easing the marginalization process because we can simply *summarize* over one</span>
<span class="sd">       dimension to achieve the effect of marginalizing over the corresponding random variable.</span>

<span class="sd">       To support the above semantics and computations, all of the arguments `particles`, `weight`, and `log_densities`</span>
<span class="sd">       must be specified in the constructor.</span>

<span class="sd">    A message can encode both type of contents, in which case the message type is ``MessageType.Both``.</span>

<span class="sd">    .. _message-arithmetic-structures-notes:</span>

<span class="sd">    Both types of messages are assumed to reside in certain vector space, and thus the appropriate arithmetic</span>
<span class="sd">    operations -- *Addition* and *Scalar Multiplication* -- are defined and implemented:</span>

<span class="sd">    * For Parameter messages,</span>

<span class="sd">        * *Addition* operation is defined as arithmetic addition on the parameter tensors.</span>
<span class="sd">        * *Scalar multiplication* is defined as arithmetic scalar multiplication with the parameter tensors.</span>
<span class="sd">        * 0 is treated as the identity element.</span>

<span class="sd">    * For Particles messages:</span>

<span class="sd">        * The following two operations are defined as operations on the particle weights, and meaningful only</span>
<span class="sd">          for Particle messages that share the same particle values and the same sampling log densities of the</span>
<span class="sd">          particles. In addition, results from these two operations are normalized so that the weight tensor</span>
<span class="sd">          sums to 1 across the sample dimensions.</span>
<span class="sd">        * *Addition* operation is defined as element-wise multiplication of particle weights tensors, up to a</span>
<span class="sd">          normalization factor.</span>
<span class="sd">        * *Scalar Multiplication* is defined as taking elements of the particle weights tensor to the power</span>
<span class="sd">          of the scalar, up to a normalization factor.</span>
<span class="sd">        * 1 is treated as the identity element for the operations.</span>
<span class="sd">        * Note that it is provably correct that the weighs with above operations form a vector space. The proof idea is</span>
<span class="sd">          to consider the log quotient space over one dimension, which reduces to standard real space with one less</span>
<span class="sd">          dimension.</span>

<span class="sd">    Accordingly, the &#39;+&#39; and &#39;*&#39; operator are overloaded according the to the specifications above.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">msg_type</span><span class="p">,</span>
                 <span class="n">batch_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">param_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">event_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">parameter</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">particles</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">log_densities</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">msg_type</span><span class="p">,</span> <span class="n">MessageType</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">batch_shape</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_shape</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="n">param_shape</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param_shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">param_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="n">sample_shape</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sample_shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample_shape</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="n">event_shape</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">event_shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">event_shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample_shape</span><span class="p">)</span>

        <span class="k">assert</span> <span class="n">parameter</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">parameter</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">particles</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">particles</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">)</span> <span class="ow">and</span>
                                     <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">particles</span><span class="p">))</span>
        <span class="k">assert</span> <span class="n">weight</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">log_densities</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">log_densities</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">)</span> <span class="ow">and</span>
                                         <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">log_densities</span><span class="p">))</span>

        <span class="c1"># Message type, of type MessageType</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="o">=</span> <span class="n">msg_type</span>
        <span class="c1"># Parameter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span> <span class="o">=</span> <span class="n">parameter</span>
        <span class="c1"># Particle list</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">particles</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">particles</span><span class="p">)</span> <span class="k">if</span> <span class="n">particles</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">log_densities</span><span class="p">)</span> <span class="k">if</span> <span class="n">log_densities</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="c1"># Additional important attributes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attr</span> <span class="o">=</span> <span class="n">kwargs</span>
        <span class="c1"># Shapes.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span> <span class="o">=</span> <span class="n">batch_shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span> <span class="o">=</span> <span class="n">param_shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span> <span class="o">=</span> <span class="n">sample_shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span> <span class="o">=</span> <span class="n">event_shape</span>

        <span class="c1"># Check whether necessary arguments are provided</span>
        <span class="k">if</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Parameter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">:</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">:</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

        <span class="c1"># Check shape and values. Adjust if necessary</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameter</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># Parameter tensor should have shape (b_shape + p_shape)</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="n">particles</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># jth particle tensor should have shape (s_shape[j] + e_shape[j])</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">)</span>
            <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># Weights tensor should have shape (b_shape + s_shape)</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span>
            <span class="c1"># Check that values are non-negative</span>
            <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">),</span> <span class="s2">&quot;Found negative values in particle weights. Minimum value: </span><span class="si">{}</span><span class="s2">&quot;</span> \
                <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">))</span>
            <span class="c1"># Normalize the values so that weights sum to 1 across sample dimension</span>
            <span class="n">sample_dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">)))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">sample_dims</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># jth log density tensor vector should have shape (s_shape[j])</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">)</span>
            <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">==</span> <span class="n">d</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span><span class="p">))</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overload arithmetic operators</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Message.__add__"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message.__add__">[docs]</a>    <span class="k">def</span> <span class="nf">__add__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;  Overloads the addition operation &#39;+&#39;</span>

<span class="sd">        Implements the semantics of addition operation as in vector spaces, but the computational operations used to</span>
<span class="sd">        implement the semantics are different for different message contents. See</span>
<span class="sd">        :ref:`Message class notes regarding arithmetic structures&lt;message-arithmetic-structures-notes&gt;`</span>
<span class="sd">        for more details.</span>

<span class="sd">        Only messages with compatible types can be added. This means a ``MessageType.Parameter`` type message can only</span>
<span class="sd">        be added with one of type ``MessageType.Parameter`` or ``MessageType.Both``, and similarly a</span>
<span class="sd">        ``MessageType.Particles`` type message can only be added with one of type ``MessageType.Particles`` or</span>
<span class="sd">        ``MessageType.Both``. ``MessageType.Both`` type message can be added with any other type except</span>
<span class="sd">        ``MessageType.Undefined``, and in any case a ``MessageType.Undefined`` type message cannot be added.</span>

<span class="sd">        There are more restrictions for ``MessageType.Particles`` type messages. Messages of such type can only be</span>
<span class="sd">        added together if their ``particles`` and ``log_densities`` fields are equal.</span>

<span class="sd">        All contents are first cloned before taking the operations and returning the result.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        other : Message</span>
<span class="sd">            The other message instance to be added together with `self`. It should have a compatible message type with</span>
<span class="sd">            `self`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Message</span>
<span class="sd">            The new message as a result of the summation.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        AssertionError</span>
<span class="sd">            If `other`&#39;s message type is incompatible with `self`.</span>
<span class="sd">        AssertionError</span>
<span class="sd">            If either `self` or `other`&#39;s message type is ``MessageType.Undefined``.</span>
<span class="sd">        AssertionError</span>
<span class="sd">            If contents of `self` and `other` have conflicting shapes.</span>
<span class="sd">        AssertionError</span>
<span class="sd">            If `self` and `other` have particles message contents to be added, but their particle values do not match,</span>
<span class="sd">            or their log sampling density tensors do not match.</span>

<span class="sd">        Warnings</span>
<span class="sd">        --------</span>
<span class="sd">        Note that all auxiliary attributes stored in ``attr``, supplied via additional keyword arguments in the Message</span>
<span class="sd">        class constructor, of both `self` and `other` will be discarded in the returning message.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Message</span><span class="p">),</span> <span class="s2">&quot;Message can only be added with another Message&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="n">other</span><span class="o">.</span><span class="n">type</span> <span class="ow">or</span> <span class="n">other</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> \
            <span class="s2">&quot;Only compatible types of messages can be added. First operand has type &#39;</span><span class="si">{}</span><span class="s2">&#39;,  while the second one has &quot;</span> \
            <span class="s2">&quot;type &#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>
        <span class="c1"># Get the small type and large type</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="n">other</span><span class="o">.</span><span class="n">type</span><span class="p">:</span>
            <span class="n">s_type</span><span class="p">,</span> <span class="n">l_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">type</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">s_type</span><span class="p">,</span> <span class="n">l_type</span> <span class="o">=</span> <span class="n">other</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span>
        <span class="c1"># Undefined type cannot be added</span>
        <span class="k">assert</span> <span class="n">s_type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Undefined</span><span class="p">,</span> \
            <span class="s2">&quot;Message of undefined type cannot be added. First operand has type &#39;</span><span class="si">{}</span><span class="s2">&#39;, while the second one has type &quot;</span> \
            <span class="s2">&quot;&#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>

        <span class="c1"># Addition for Parameter type</span>
        <span class="n">new_msg</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Parameter</span> <span class="ow">in</span> <span class="n">s_type</span><span class="p">:</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">b_shape</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> \
                <span class="s2">&quot;Only Messages with the same shape can be added together. The messages being added are of Parameter &quot;</span> \
                <span class="s2">&quot;type. Found first message with (batch_shape, param_shape) = &#39;</span><span class="si">{}</span><span class="s2">&#39;, and second message with &quot;</span> \
                <span class="s2">&quot;(batch_shape, param_shape) = &#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">),</span> <span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">p_shape</span><span class="p">))</span>
            <span class="c1"># Tensor addition</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter</span> <span class="o">+</span> <span class="n">other</span><span class="o">.</span><span class="n">parameter</span>

            <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">batch_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">param_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="n">parameters</span><span class="o">=</span><span class="n">new_parameters</span><span class="p">)</span>

        <span class="c1"># Addition for Particles type</span>
        <span class="k">if</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span> <span class="ow">in</span> <span class="n">s_type</span><span class="p">:</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">b_shape</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">s_shape</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span> \
                <span class="s2">&quot;Only Messages with the same shape can be added together. The messages being added are of Particles &quot;</span> \
                <span class="s2">&quot;type. Found first message with (batch_shape, sample_shape, event_shape) = &#39;</span><span class="si">{}</span><span class="s2">&#39;, and second message &quot;</span> \
                <span class="s2">&quot;with (batch_shape, sample_shape, event_shape) = &#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span> \
                    <span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">),</span> <span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">e_shape</span><span class="p">))</span>
            <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">self_p</span><span class="p">,</span> <span class="n">other_p</span><span class="p">)</span> <span class="k">for</span> <span class="n">self_p</span><span class="p">,</span> <span class="n">other_p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">particles</span><span class="p">)),</span> \
                <span class="s2">&quot;For particle messages, only ones with matching particle values can be added together. &quot;</span>
            <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">self_d</span><span class="p">,</span> <span class="n">other_d</span><span class="p">)</span> <span class="k">for</span> <span class="n">self_d</span><span class="p">,</span> <span class="n">other_d</span> <span class="ow">in</span>
                       <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">log_densities</span><span class="p">)),</span> \
                <span class="s2">&quot;For particle messages, only ones with matching log sampling densities can be added together&quot;</span>

            <span class="c1"># Take element-wise product</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">*</span> <span class="n">other</span><span class="o">.</span><span class="n">weight</span>
            <span class="c1"># Clone self tensor contents</span>
            <span class="n">cloned_particles</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">)</span>
            <span class="n">cloned_log_densities</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_densities</span><span class="p">)</span>

            <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                              <span class="n">sample_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">batch_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">event_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                              <span class="n">particles</span><span class="o">=</span><span class="n">cloned_particles</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">new_weights</span><span class="p">,</span> <span class="n">log_density</span><span class="o">=</span><span class="n">cloned_log_densities</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">new_msg</span></div>

    <span class="k">def</span> <span class="nf">__iadd__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Overloading self-addition operator &#39;+=&#39;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__add__</span><span class="p">(</span><span class="n">other</span><span class="p">)</span>

<div class="viewcode-block" id="Message.__mul__"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message.__mul__">[docs]</a>    <span class="k">def</span> <span class="nf">__mul__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Overloading multiplication operator &#39;*&#39;. Implements scalar multiplication semantics.</span>

<span class="sd">            The scalar can be of type int, float, or torch.Tensor. If it is a torch.Tensor, can be a singleton tensor</span>
<span class="sd">                representing a single scalar, or a tensor of shape batch_shape representing a batched scalars.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)),</span> \
            <span class="s2">&quot;Message can only be multiplied with a scalar. The scalar can be of int, float or torch.Tensor type. &quot;</span> \
            <span class="s2">&quot;Instead found: &#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">other</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">assert</span> <span class="n">other</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([])</span> <span class="ow">or</span> <span class="n">other</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> \
                <span class="s2">&quot;If the scalar is a torch.Tensor, must be either a singleton tensor or a tensor with the same shape &quot;</span> \
                <span class="s2">&quot;as the Message&#39;s batch shape: &#39;</span><span class="si">{}</span><span class="s2">&#39;. Instead found: &#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="c1"># Undefined type cannot be scalar multiplied</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Undefined</span><span class="p">,</span> \
            <span class="s2">&quot;Message of undefined type cannot be scalar multiplied. The message has type &#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span> \
            <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>

        <span class="c1"># Expand scalar tensor dimension if it is a batched scalars</span>
        <span class="n">b_p_other</span> <span class="o">=</span> <span class="n">other</span>
        <span class="n">s_b_other</span> <span class="o">=</span> <span class="n">other</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">other</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="ow">is</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Parameter</span><span class="p">:</span>
                <span class="n">b_p_other</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">b_p_other</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="ow">is</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span><span class="p">:</span>
                <span class="n">s_b_other</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">s_b_other</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Scalar multiplication for Parameter messages</span>
        <span class="n">new_msg</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Parameter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">:</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">b_p_other</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span>
            <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">batch_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">param_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="n">parameters</span><span class="o">=</span><span class="n">new_parameters</span><span class="p">,</span>
                              <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>

        <span class="c1"># Scalar multiplication for Particles messages</span>
        <span class="k">if</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">:</span>
            <span class="c1"># The result of scalar multiplication with uniform weights is still uniform, so only process non-uniform</span>
            <span class="c1">#   weights</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_weights</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="c1"># Extract int/float from singleton scalar tensor</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">s_b_other</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">s_b_other</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">s_b_other</span> <span class="o">=</span> <span class="n">s_b_other</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="c1"># Take weights tensor to the power of the scaler</span>
                <span class="n">new_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">new_weights</span><span class="p">,</span> <span class="n">s_b_other</span><span class="p">)</span>

            <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                              <span class="n">sample_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">batch_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">event_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                              <span class="n">particles</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">new_weights</span><span class="p">,</span> <span class="n">log_density</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log_density</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">new_msg</span></div>

    <span class="k">def</span> <span class="nf">__imul__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Overloading self-multiplication operator &#39;*=&#39;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__mul__</span><span class="p">(</span><span class="n">other</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Parameter</span><span class="p">:</span>
            <span class="n">b_shape_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">))</span>
            <span class="n">p_shape_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">))</span>
            <span class="n">parameters_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>

            <span class="k">return</span> <span class="n">f</span><span class="s2">&quot;Type: Parameter</span><span class="se">\n</span><span class="s2">Batch_Shape: </span><span class="si">{b_shape_str}</span><span class="se">\n</span><span class="s2">Parameter_Shape: </span><span class="si">{p_shape_str}</span><span class="se">\n</span><span class="s2">&quot;</span> \
                   <span class="n">f</span><span class="s2">&quot;Parameters</span><span class="si">{parameters_str}</span><span class="s2">&quot;</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">s_shape_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">))</span>
            <span class="n">b_shape_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">))</span>
            <span class="n">e_shape_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">))</span>
            <span class="n">particles_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>
            <span class="n">weights_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>
            <span class="n">log_density_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_density</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>

            <span class="k">return</span> <span class="n">f</span><span class="s2">&quot;Type: Particles</span><span class="se">\n</span><span class="s2">Sample_Shape: </span><span class="si">{s_shape_str}</span><span class="se">\n</span><span class="s2">Batch_Shape: </span><span class="si">{b_shape_str}</span><span class="se">\n</span><span class="s2">&quot;</span> \
                   <span class="n">f</span><span class="s2">&quot;Event_Shape: </span><span class="si">{e_shape_str}</span><span class="se">\n</span><span class="s2">Particles: </span><span class="si">{particles_str}</span><span class="se">\n</span><span class="s2">&quot;</span> \
                   <span class="n">f</span><span class="s2">&quot;Weights: </span><span class="si">{weights_str}</span><span class="se">\n</span><span class="s2">Log_Density: </span><span class="si">{log_density_str}</span><span class="s2">&quot;</span>

<div class="viewcode-block" id="Message.size"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message.size">[docs]</a>    <span class="k">def</span> <span class="nf">size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Returns a tuple of the message&#39;s shapes:</span>
<span class="sd">                (sample_shape, batch_shape, param_shape, event_shape)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span></div>

<div class="viewcode-block" id="Message.same_size_as"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message.same_size_as">[docs]</a>    <span class="k">def</span> <span class="nf">same_size_as</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Check if self has the same shape as the other message. Return True if so.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Message</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">size</span><span class="p">()</span></div>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Methods for operations on the message instance itself.</span>
<span class="sd">        &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Message.reduce_type"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message.reduce_type">[docs]</a>    <span class="k">def</span> <span class="nf">reduce_type</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">msg_type</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Return a &#39;msg_type&#39; type reduced self message, where irrelevant components w.r.t. &#39;msg_type&#39; is removed, and</span>
<span class="sd">                the relevant components are retained and cloned.</span>

<span class="sd">            Return self and do nothing if msg_type is self type.</span>

<span class="sd">            :param msg_type:        MessageType.Parameter or MessageType.Particles.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">msg_type</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> \
            <span class="s2">&quot;Target message type &#39;</span><span class="si">{}</span><span class="s2">&#39; is not compatible with self message type &#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">msg_type</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">msg_type</span> <span class="ow">is</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Parameter</span> <span class="ow">or</span> <span class="n">msg_type</span> <span class="ow">is</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span><span class="p">,</span> \
            <span class="s2">&quot;The target message type can only be Parameter or Particles. &quot;</span>

        <span class="k">if</span> <span class="n">msg_type</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>

        <span class="c1"># First clone content</span>
        <span class="n">cloned_msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">msg_type</span> <span class="o">==</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Parameter</span><span class="p">:</span>
            <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">param_shape</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="n">batch_shape</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span>
                              <span class="n">parameters</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="o">**</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">sample_shape</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">batch_shape</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span>
                              <span class="n">event_shape</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span> <span class="n">particles</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">particles</span><span class="p">,</span>
                              <span class="n">weights</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">log_density</span><span class="o">=</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">log_density</span><span class="p">,</span> <span class="o">**</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.clone"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message.clone">[docs]</a>    <span class="k">def</span> <span class="nf">clone</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Return a cloned message from self. Guarantees that every content is deep-copied. Tensors will be cloned and</span>
<span class="sd">                dictionaries will be deep-copied.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span>
        <span class="n">particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="n">log_density</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_density</span>
        <span class="n">attr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attr</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">parameters</span> <span class="o">=</span> <span class="n">parameters</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">particles</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">particles</span> <span class="o">=</span> <span class="n">particles</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">log_density</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">log_density</span> <span class="o">=</span> <span class="n">log_density</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">attr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">attr</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">parameters</span><span class="p">,</span> <span class="n">particles</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">log_density</span><span class="p">,</span> <span class="o">**</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Methods for batch dimension manipulations. </span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Message.batch_permute"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message.batch_permute">[docs]</a>    <span class="k">def</span> <span class="nf">batch_permute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target_dims</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Returns a permuted message whose tensor attributes are permuted from the original ones w.r.t. &#39;target_dims&#39;</span>
<span class="sd">                in the batch dimensions.</span>
<span class="sd">            Note that target_dims is relative to the batch dimension. Its values should be within the range</span>
<span class="sd">                    [-len(batch_shape), len(batch_shape) - 1]</span>

<span class="sd">            contiguous() will be called before return to make sure the resulting content tensors are contiguous</span>

<span class="sd">            This method is a mimic of torch.Tensor.permute()</span>

<span class="sd">            :param target_dims:     list of ints. The desired ordering batch dimensions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target_dims</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">target_dims</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_dims</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="ow">and</span> \
               <span class="nb">all</span><span class="p">(</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">target_dims</span><span class="p">)</span>

        <span class="c1"># Translate negative dims to nonnegative value</span>
        <span class="n">pos_target_dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">target_dims</span><span class="p">)</span> <span class="o">+</span> <span class="n">i</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">target_dims</span><span class="p">)</span>
        <span class="c1"># Permuted batch shape</span>
        <span class="n">new_b_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">pos_target_dims</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">))))</span>
        <span class="c1"># Permute order for sample and batch dimensions together.</span>
        <span class="c1">#   Add 1 to values in pos_target_dims because there&#39;s a single sample dimensions at front</span>
        <span class="n">s_b_dims</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">pos_target_dims</span><span class="p">)</span>
        <span class="c1"># Permute order for batch and parameter dimensions together</span>
        <span class="n">b_p_dims</span> <span class="o">=</span> <span class="n">pos_target_dims</span> <span class="o">+</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)]</span>

        <span class="n">new_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="n">new_log_density</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_density</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">b_p_dims</span><span class="p">)</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">new_parameters</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (s_shape + b_shape)</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">s_b_dims</span><span class="p">)</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="n">new_weights</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameters</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weights</span><span class="p">,</span> <span class="n">new_log_density</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_unsqueeze"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message.batch_unsqueeze">[docs]</a>    <span class="k">def</span> <span class="nf">batch_unsqueeze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Returns a new message with a dimension of size one inserted at the specified batch dimension, similar to</span>
<span class="sd">                torch.unsqueeze().</span>
<span class="sd">            A &#39;dim&#39; value within the range [-len(batch_shape) - 1, len(batch_shape) + 1] can be used. Note that &#39;dim&#39;</span>
<span class="sd">                is relative to the batch dimension only.</span>

<span class="sd">            This method is a mimic of torch.unsqueeze()</span>

<span class="sd">            :param dim:     an int. The place where the new dimension of size one will be inserted at.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">&lt;=</span> <span class="n">dim</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># Translate dim to positive value if it is negative</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="c1"># For message contents who has a sample dimension at front, add 1 to dim</span>
        <span class="n">s_dim</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="c1"># Get new batch shape</span>
        <span class="n">new_b_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">:]</span>

        <span class="n">new_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="n">new_log_density</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_density</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (s_shape + b_shape)</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">s_dim</span><span class="p">)</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameters</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weights</span><span class="p">,</span> <span class="n">new_log_density</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_index_select"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message.batch_index_select">[docs]</a>    <span class="k">def</span> <span class="nf">batch_index_select</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Returns a new Message which indexes the input message along batch dimension dim using the entries in index</span>
<span class="sd">                which is a LongTensor.</span>
<span class="sd">            A &#39;dim&#39; value within the range [-len(batch_shape), len(batch_shape) - 1] can be used. Note that &#39;dim&#39;</span>
<span class="sd">                is relative to the batch dimension only.</span>

<span class="sd">            This method is a mimic of batch_index_select()</span>

<span class="sd">            :param dim:     an int. The dimension along which entries will be selected according to &#39;index&#39;</span>
<span class="sd">            :param index:   torch.LongTensor. The index of entries along &#39;dim&#39; to be selected</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">dim</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">index</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span>

        <span class="c1"># Translate dim to positive value if it is negative</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">dim</span>
        <span class="c1"># For message contents who has a sample dimension at front, add 1 to dim</span>
        <span class="n">s_dim</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="c1"># Get new batch shape</span>
        <span class="n">new_b_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="n">index</span><span class="o">.</span><span class="n">shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span>

        <span class="n">new_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="n">new_log_density</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_density</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (s_shape + b_shape)</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">s_dim</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameters</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weights</span><span class="p">,</span> <span class="n">new_log_density</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_index_put"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message.batch_index_put">[docs]</a>    <span class="k">def</span> <span class="nf">batch_index_put</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Returns a new Message whose entries along the dimension &#39;dim&#39; are slices from self message and are indexed</span>
<span class="sd">                by &#39;index&#39;. Effectively, along the dimension &#39;dim&#39;:</span>
<span class="sd">                    result_msg[..., index[i], ...] = val[i]</span>

<span class="sd">            For slices in the new message not referenced by &#39;index&#39;, they will be filled with identity values. For</span>
<span class="sd">                Parameter type message, the identity value is 0; for Particles type message, the identity value is 1,</span>
<span class="sd">                up to a normalization factor.</span>

<span class="sd">            This method is the inverted version of batch_index_select(). There is no direct counterpart to this method</span>
<span class="sd">                in PyTorch.</span>

<span class="sd">            :param dim:     an int. Specifying a dimension of the message. Should be in range</span>
<span class="sd">                                        [-len(batch_shape), len(batch_shape) - 1]</span>
<span class="sd">            :param index:   a LongTensor. Specifying the indices along the specified dimension of the returned message.</span>
<span class="sd">                                Entries must be non-negative.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">dim</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">index</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">index</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Translate dim value to positive if it&#39;s negative</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">dim</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">dim</span>
        <span class="c1"># For message contents who has a sample dimension at front, add 1 to dim</span>
        <span class="n">s_dim</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="c1"># Get new batch shape. The size of dimension dim is determined by the maximum value in index</span>
        <span class="n">new_b_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span>

        <span class="n">new_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="n">new_log_density</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_density</span>

        <span class="c1"># To access tensor slice more easily, we swap the target dim with first dim, perform slicing and assignment on</span>
        <span class="c1">#   this new first dim, and swap it back</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="c1"># Identity value tensor</span>
            <span class="n">to_fill</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">new_b_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">)</span>
            <span class="c1"># Transpose target dimension with the first dimension</span>
            <span class="n">to_fill</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">to_fill</span><span class="p">,</span> <span class="n">dim0</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
            <span class="n">t_param</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">new_parameters</span><span class="p">,</span> <span class="n">dim0</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
            <span class="c1"># Slice and assign</span>
            <span class="n">to_fill</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">t_param</span>
            <span class="c1"># Transpose back to get result</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">to_fill</span><span class="p">,</span> <span class="n">dim0</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (s_shape + b_shape)</span>
            <span class="c1"># Identity value tensor</span>
            <span class="n">to_fill</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span> <span class="o">+</span> <span class="n">new_b_shape</span><span class="p">)</span>
            <span class="c1"># Transpose target dimension with the first dimension</span>
            <span class="n">to_fill</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">to_fill</span><span class="p">,</span> <span class="n">dim0</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="n">s_dim</span><span class="p">)</span>
            <span class="n">t_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">new_weights</span><span class="p">,</span> <span class="n">dim0</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="n">s_dim</span><span class="p">)</span>
            <span class="c1"># Slice and assign</span>
            <span class="n">to_fill</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">t_weights</span>
            <span class="c1"># Transpose back to get result</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">to_fill</span><span class="p">,</span> <span class="n">dim0</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="n">s_dim</span><span class="p">)</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameters</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weights</span><span class="p">,</span> <span class="n">new_log_density</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_diagonal"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message.batch_diagonal">[docs]</a>    <span class="k">def</span> <span class="nf">batch_diagonal</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Returns a partial view of self with the its diagonal elements with respect to &#39;dim1&#39; and &#39;dim2&#39; appended as</span>
<span class="sd">                a dimension at the end of the shape.</span>
<span class="sd">            dim values within the range [-len(batch_shape), len(batch_shape) - 1] can be used.</span>
<span class="sd">            Note that &#39;dim1&#39; and &#39;dim2&#39; are relative to the batch dimension. The appended dimension will be placed as</span>
<span class="sd">                the last batch dimension, but before any event or param dimension.</span>

<span class="sd">            contiguous() will be called before return to make sure the resulting content tensors are contiguous</span>

<span class="sd">            This method is a mimic of torch.diagonal(), with offset default to 0</span>

<span class="sd">            :param dim1:    an int. Should be in range [-len(batch_shape), len(batch_shape) - 1]</span>
<span class="sd">            :param dim2.    Same as &#39;dim1&#39;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim1</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">dim1</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim2</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">dim2</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

        <span class="c1"># Translate dim value to positive if it&#39;s negative</span>
        <span class="n">dim1</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">dim1</span> <span class="k">if</span> <span class="n">dim1</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">dim1</span>
        <span class="n">dim2</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">dim2</span> <span class="k">if</span> <span class="n">dim2</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">dim2</span>
        <span class="c1"># For message contents who has a sample dimension at front, add 1 to dim</span>
        <span class="n">s_dim1</span> <span class="o">=</span> <span class="n">dim1</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">s_dim2</span> <span class="o">=</span> <span class="n">dim2</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="c1"># Get new batch shape. The size of the appended diagonalized dimension should be the min of dim1 and dim2</span>
        <span class="n">new_b_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[:</span><span class="nb">min</span><span class="p">(</span><span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">)]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span> <span class="nb">max</span><span class="p">(</span><span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">)]</span> <span class="o">+</span> \
                      <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="nb">max</span><span class="p">(</span><span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim2</span><span class="p">])])</span>

        <span class="n">new_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="n">new_log_density</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_density</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">new_parameters</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="n">dim2</span><span class="p">)</span>
            <span class="c1"># Swap param dimension and appended diagonal batch dimension</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">new_parameters</span><span class="p">,</span> <span class="n">dim0</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">new_parameters</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (s_shape + b_shape)</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">new_weights</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="n">s_dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="n">s_dim2</span><span class="p">)</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="n">new_weights</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameters</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weights</span><span class="p">,</span> <span class="n">new_log_density</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_diag_embed"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message.batch_diag_embed">[docs]</a>    <span class="k">def</span> <span class="nf">batch_diag_embed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">diag_dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">target_dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">target_dim2</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Creates a message whose diagonals of certain 2D planes (dimensions specified by &#39;target_dim1&#39; and</span>
<span class="sd">                &#39;target_dim2&#39;) are filled by vectors of self (dimension specified by &#39;diag_dim&#39;). The last dimension of</span>
<span class="sd">                self is chosen by default as the diagonal entries to be filled, and the last two dimensions of the new</span>
<span class="sd">                message are chosen by default as the 2D planes where the diagonal entries will be filled in.</span>

<span class="sd">            The 2D planes will be shaped as square matrices, with the size of each dimension matches the size of the</span>
<span class="sd">                diag_dim in self.</span>

<span class="sd">            The length of returned message&#39;s batch shape will be the length of original message&#39;s batch shape plus 1.</span>

<span class="sd">            For slots not on the diagonal of the resulting message, they will be filled with identity values. For</span>
<span class="sd">                Parameter type message, the identity value is 0 w.r.t. the parameter tensor, and for Particles type</span>
<span class="sd">                message, the identity value is 1 w.r.t. the weights tensor up to a normalization factor.</span>

<span class="sd">            contiguous() will be called before return to make sure the resulting content tensors are contiguous</span>

<span class="sd">            This method is a mimic of torch.diag_embed(), with offset default to 0 plus an additional diag_dim argument.</span>

<span class="sd">            :param diag_dim:        an int. Specifying a dimension of the original message. Should be in range</span>
<span class="sd">                                        [-len(batch_shape), len(batch_shape) - 1]</span>
<span class="sd">            :param target_dim1:     an int. Specifying a dimension of the returned message. Should be in range</span>
<span class="sd">                                        [-len(batch_shape) - 1, len(batch_shape)]</span>
<span class="sd">            :param target_dim2:     Same as &#39;target_dim1&#39;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">diag_dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">diag_dim</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target_dim1</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">&lt;=</span> <span class="n">target_dim1</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target_dim2</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">&lt;=</span> <span class="n">target_dim2</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span>

        <span class="c1"># Translate dim value to positive if it&#39;s negative</span>
        <span class="n">diag_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">diag_dim</span> <span class="k">if</span> <span class="n">diag_dim</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">diag_dim</span>
        <span class="n">target_dim1</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">target_dim1</span> <span class="k">if</span> <span class="n">target_dim1</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">target_dim1</span>
        <span class="n">target_dim2</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">target_dim2</span> <span class="k">if</span> <span class="n">target_dim2</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">target_dim2</span>
        <span class="c1"># For message contents who has a sample dimension at front, add 1 to dim</span>
        <span class="n">s_diag_dim</span> <span class="o">=</span> <span class="n">diag_dim</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">s_target_dim1</span> <span class="o">=</span> <span class="n">target_dim1</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">s_target_dim2</span> <span class="o">=</span> <span class="n">target_dim2</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="c1"># Get new batch shape. The size of target_dim1 and target_dim2 is determined by the size of diag_dim</span>
        <span class="n">diag_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">diag_dim</span><span class="p">]</span>
        <span class="n">other_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[:</span><span class="n">diag_dim</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">diag_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:])</span>
        <span class="n">first_new_dim</span><span class="p">,</span> <span class="n">second_new_dim</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">target_dim1</span><span class="p">,</span> <span class="n">target_dim2</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">target_dim1</span><span class="p">,</span> <span class="n">target_dim2</span><span class="p">)</span>
        <span class="n">other_shape</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">first_new_dim</span><span class="p">,</span> <span class="n">diag_size</span><span class="p">)</span>
        <span class="n">other_shape</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">second_new_dim</span><span class="p">,</span> <span class="n">diag_size</span><span class="p">)</span>
        <span class="n">new_b_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="n">other_shape</span><span class="p">)</span>

        <span class="n">new_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="n">new_log_density</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_density</span>

        <span class="c1"># Tensors fist need to have the diagonal entries dimension (diag_dim) permuted to the last dimension so that it</span>
        <span class="c1">#   will be picked up by torch.diag_embed()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">perm_order</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">)))</span>
            <span class="n">perm_order</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">diag_dim</span><span class="p">)</span>
            <span class="n">perm_order</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">diag_dim</span><span class="p">)</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">new_parameters</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">perm_order</span><span class="p">)</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag_embed</span><span class="p">(</span><span class="n">new_parameters</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="n">target_dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="n">target_dim2</span><span class="p">)</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">new_parameters</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (s_shape + b_shape)</span>
            <span class="c1"># For weights, the default entries to be filled in places other than the diagonal should be 1&#39;s, so we</span>
            <span class="c1">#   will first fill the log of input into the diagonal and then take exponential. 0&#39;s filled by</span>
            <span class="c1">#   torch.diag_embed() will be transformed to 1. Note that for these uniform entries the weights will be</span>
            <span class="c1">#   normalized across sample dimension during initialization so no worries.</span>
            <span class="n">log_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">new_weights</span><span class="p">)</span>
            <span class="n">perm_order</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)))</span>
            <span class="n">perm_order</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">s_diag_dim</span><span class="p">)</span>
            <span class="n">perm_order</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s_diag_dim</span><span class="p">)</span>
            <span class="n">log_weights</span> <span class="o">=</span> <span class="n">log_weights</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">perm_order</span><span class="p">)</span>
            <span class="n">log_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag_embed</span><span class="p">(</span><span class="n">log_weights</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="n">s_target_dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="n">s_target_dim2</span><span class="p">)</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_weights</span><span class="p">)</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="n">new_weights</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameters</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weights</span><span class="p">,</span> <span class="n">new_log_density</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_narrow"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message.batch_narrow">[docs]</a>    <span class="k">def</span> <span class="nf">batch_narrow</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">length</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Returns a new message that is a narrowed version of input tensor along the dimension specified by &#39;dim&#39;.</span>
<span class="sd">                Effectively, this method is selecting the chunk spanning [:length] along the dimension &#39;dim&#39; of the</span>
<span class="sd">                original message. The returned message and input message share the same underlying storage.</span>

<span class="sd">            contiguous() will be called before return to make sure the resulting content tensors are contiguous</span>

<span class="sd">            This method is a mimic of torch.narrow(), with start default to 0.</span>

<span class="sd">            :param dim      an int. Specifying a dimension of the original message. Should be in range</span>
<span class="sd">                                        [-len(batch_shape), len(batch_shape) - 1]</span>
<span class="sd">            :param length   an int. Specifying the length of the message chunk to select. Should be in range</span>
<span class="sd">                                        [0, dim_size - 1]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">dim</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">length</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">length</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>

        <span class="c1"># Translate dim value to positive if it&#39;s negative</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">dim</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">dim</span>
        <span class="c1"># For message contents who has a sample dimension at front, add 1 to dim</span>
        <span class="n">s_dim</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="c1"># Get new batch shape.</span>
        <span class="n">new_b_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">length</span><span class="p">])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span>

        <span class="n">new_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="n">new_log_density</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_density</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">narrow</span><span class="p">(</span><span class="n">new_parameters</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="n">length</span><span class="p">)</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">new_parameters</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (s_shape + b_shape)</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">narrow</span><span class="p">(</span><span class="n">new_weights</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">s_dim</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="n">length</span><span class="p">)</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="n">new_weights</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameters</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weights</span><span class="p">,</span> <span class="n">new_log_density</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_broaden"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message.batch_broaden">[docs]</a>    <span class="k">def</span> <span class="nf">batch_broaden</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">length</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Returns a new message that is a broadened version of the input tensor along the dimension specified by</span>
<span class="sd">                &#39;dim&#39;, with identity values filled in [dim_size + 1: length] along the dimension &#39;dim&#39; of the original</span>
<span class="sd">                message. In other words, this method is concatenating an identity message to the original message along</span>
<span class="sd">                the dimension &#39;dim&#39; so that the resulting dimension size is &#39;length&#39;.</span>

<span class="sd">            For Parameter type message, the identity values are 0. For Particles type message, the identity values are 1</span>
<span class="sd">                up to a normalization factor.</span>

<span class="sd">            contiguous() will be called before return to make sure the resulting content tensors are contiguous</span>

<span class="sd">            This method is the inverted version of batch_narrow(). There is no direct counterpart to this method in</span>
<span class="sd">                PyTorch.</span>

<span class="sd">            :param dim      an int. Specifying a dimension of the original message. Should be in range</span>
<span class="sd">                                        [-len(batch_shape), len(batch_shape) - 1]</span>
<span class="sd">            :param length   an int. Specifying the length of the message chunk to select. Should be greater than the</span>
<span class="sd">                                current size of dimension &#39;dim&#39;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">dim</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">length</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">length</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>

        <span class="c1"># Translate dim value to positive if it&#39;s negative</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">dim</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">dim</span>
        <span class="c1"># For message contents who has a sample dimension at front, add 1 to dim</span>
        <span class="n">s_dim</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="c1"># Get new batch shape.</span>
        <span class="n">new_b_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">length</span><span class="p">])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Parameter</span><span class="p">:</span>
            <span class="n">to_concat_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">length</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]])</span> <span class="o">+</span> \
                              <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">to_concat_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">length</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]])</span> <span class="o">+</span> \
                              <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span>

        <span class="n">new_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="n">new_log_density</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_density</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">to_concat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">to_concat_shape</span><span class="p">)</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">new_parameters</span><span class="p">,</span> <span class="n">to_concat</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">new_parameters</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (s_shape + b_shape)</span>
            <span class="n">to_concat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">to_concat_shape</span><span class="p">)</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">new_weights</span><span class="p">,</span> <span class="n">to_concat</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="n">s_dim</span><span class="p">)</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="n">new_weights</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameters</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weights</span><span class="p">,</span> <span class="n">new_log_density</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_summarize"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message.batch_summarize">[docs]</a>    <span class="k">def</span> <span class="nf">batch_summarize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Implements the default Sum-Product summarization semantics. Summarizes over the batch dimension specified by</span>
<span class="sd">                &#39;dim&#39;. Returns a message with one less dimension.</span>

<span class="sd">            For Parameter message, the summarization is realized by taking the mean value of the batched parameters</span>
<span class="sd">                across dimension &#39;dim&#39;. For particles message, this is realized by taking joint addition defined for</span>
<span class="sd">                particle weights, a.k.a. factor product.</span>

<span class="sd">            :param dim:     an int. Specifying a dimension of the original message. Should be in range</span>
<span class="sd">                                        [-len(batch_shape), len(batch_shape) - 1]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">dim</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

        <span class="c1"># Translate dim value to positive if it&#39;s negative</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">dim</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">dim</span>
        <span class="c1"># For message contents who has a sample dimension at front, add 1 to dim</span>
        <span class="n">s_dim</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="c1"># Get new batch shape.</span>
        <span class="n">new_b_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span>

        <span class="n">new_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="n">new_log_density</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_density</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">new_parameters</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (s_shape + b_shape)</span>
            <span class="c1"># For weights, since factor product is taken, we first convert weight values to log scale, perform summation</span>
            <span class="c1">#   across the batch dimension, then convert back to exponential scale.</span>
            <span class="c1"># The normalization of resulting weights will be taken care of by message initialization</span>
            <span class="n">log_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">new_weights</span><span class="p">)</span>
            <span class="n">log_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_weights</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">s_dim</span><span class="p">)</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_weights</span><span class="p">)</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameters</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weights</span><span class="p">,</span> <span class="n">new_log_density</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_flatten"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message.batch_flatten">[docs]</a>    <span class="k">def</span> <span class="nf">batch_flatten</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Flattens the set of batch dimensions specified by &#39;dims&#39; and append the flattened dimension as the last</span>
<span class="sd">                dimension. If &#39;dims&#39; is None, will flatten all batch dimensions into a single dimension.</span>

<span class="sd">            contiguous() will be called before return to make sure the resulting content tensors are contiguous</span>

<span class="sd">            :param dims:    None or an Iterable of ints. Specifying the set of dimensions to be flattened. If given,</span>
<span class="sd">                                each value should be in range   [-len(batch_shape), len(batch_shape) - 1]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">dims</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">dims</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span>
                                <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">dim</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">dims</span><span class="p">))</span>

        <span class="c1"># Translate dim value to positive if it&#39;s negative</span>
        <span class="n">dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">dim</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">dim</span> <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">dims</span><span class="p">)</span> <span class="k">if</span> <span class="n">dims</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> \
               <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)))</span>
        <span class="n">other_dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">))</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">dims</span><span class="p">)</span>
        <span class="c1"># For message contents who has a sample dimension at front, add 1 to dim</span>
        <span class="n">s_dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">dims</span><span class="p">)</span>
        <span class="n">s_other_dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">other_dims</span><span class="p">)</span>
        <span class="c1"># Get new batch shape.</span>
        <span class="n">new_b_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">))</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">dims</span><span class="p">))</span> <span class="o">+</span> \
                      <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)[</span><span class="n">dims</span><span class="p">])])</span>

        <span class="n">new_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="n">new_log_density</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_density</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">perm_order</span> <span class="o">=</span> <span class="n">other_dims</span> <span class="o">+</span> <span class="n">dims</span> <span class="o">+</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)]</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">new_parameters</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">perm_order</span><span class="p">)</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">new_parameters</span><span class="p">,</span> <span class="n">start_dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">other_dims</span><span class="p">),</span> <span class="n">end_dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">new_parameters</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (s_shape + b_shape)</span>
            <span class="n">perm_order</span> <span class="o">=</span> <span class="n">s_other_dims</span> <span class="o">+</span> <span class="n">s_dims</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="n">new_weights</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">perm_order</span><span class="p">)</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">new_weights</span><span class="p">,</span> <span class="n">start_dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">s_other_dims</span><span class="p">),</span> <span class="n">end_dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="n">new_weights</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_b_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameters</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weights</span><span class="p">,</span> <span class="n">new_log_density</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_reshape"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message.batch_reshape">[docs]</a>    <span class="k">def</span> <span class="nf">batch_reshape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_batch_shape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Returns a message with the same data as self, but with the specified &#39;new_batch_shape&#39;.</span>

<span class="sd">            This method is a mimic of torch.reshape()</span>

<span class="sd">            :param new_batch_shape:     Iterable of python ints, or torch.Size. The target batch shape.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span> <span class="ow">or</span> \
               <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">new_batch_shape</span><span class="p">))</span>

        <span class="n">new_batch_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">))</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="k">else</span> \
            <span class="n">new_batch_shape</span>

        <span class="n">new_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="n">new_log_density</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_density</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">new_parameters</span><span class="p">,</span> <span class="n">new_batch_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (s_shape + b_shape)</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">new_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span> <span class="o">+</span> <span class="n">new_batch_shape</span><span class="p">)</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_batch_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameters</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weights</span><span class="p">,</span> <span class="n">new_log_density</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.batch_expand"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message.batch_expand">[docs]</a>    <span class="k">def</span> <span class="nf">batch_expand</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_batch_shape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Returns a new view of the self message with singleton batch dimensions expanded to a larger size.</span>

<span class="sd">            Passing a -1 as the size for a dimension means not changing the size of that dimension.</span>

<span class="sd">            Expanding a message would not allocate new memory for the tensor contents, but create a new view on the</span>
<span class="sd">                existing tensor. Any dimension of size 1 can be expanded to an arbitrary value without allocating new</span>
<span class="sd">                memory.</span>

<span class="sd">            Note that more than one element of an expanded message may refer to a single memory location. As a result,</span>
<span class="sd">                in-place operations may result in incorrect behavior. Clone first before needing to write in-place to</span>
<span class="sd">                the message tensor contents.</span>

<span class="sd">            This method is a mimic of torch.expand()</span>

<span class="sd">            :param new_batch_shape:     Iterable of python ints, or torch.Size. The target expanded batch shape. Must</span>
<span class="sd">                                            have the same length as self&#39;s current batch shape.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span> <span class="ow">or</span> \
               <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">new_batch_shape</span><span class="p">))</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">))</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_shape</span><span class="p">)</span>

        <span class="n">new_batch_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">))</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_batch_shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="k">else</span> \
            <span class="n">new_batch_shape</span>

        <span class="n">new_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="n">new_log_density</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_density</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># parameters has shape (b_shape + p_shape)</span>
            <span class="n">new_shape</span> <span class="o">=</span> <span class="n">new_batch_shape</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">new_parameters</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">new_shape</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># weights has shape (s_shape + b_shape)</span>
            <span class="n">new_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span> <span class="o">+</span> <span class="n">new_batch_shape</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="n">new_weights</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">new_shape</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">new_batch_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameters</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">new_weights</span><span class="p">,</span> <span class="n">new_log_density</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Methods for Manipulations on message events </span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="Message.event_transform"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message.event_transform">[docs]</a>    <span class="k">def</span> <span class="nf">event_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trans</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Apply a transformation on the event values. Return the transformed message.</span>

<span class="sd">            Message contents will be cloned.</span>

<span class="sd">            For particles:</span>
<span class="sd">                - Apply the transformation directly on the particle values</span>
<span class="sd">                - Log sampling densities will be adjusted by adding the log abs determinant of the Jacobian of the</span>
<span class="sd">                    transformation:</span>
<span class="sd">                            log P(Y) = log P(X) + log |det (dX / dY)|</span>
<span class="sd">                - Weights are kept the same, but the tensor will be cloned.</span>

<span class="sd">            For parameters:</span>
<span class="sd">                - Raise an alert if &#39;dist_class&#39; attribute is missing in self.attr</span>
<span class="sd">                - Query DistributionServer to obtained the transformed parameter.</span>

<span class="sd">            :param trans:     torch.distributions.transforms.Transform. The transformation functor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">trans</span><span class="p">,</span> <span class="n">Transform</span><span class="p">)</span>

        <span class="c1"># First clone</span>
        <span class="n">cloned_msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">cloned_msg</span><span class="o">.</span><span class="n">parameters</span>
        <span class="n">new_particles</span> <span class="o">=</span> <span class="n">cloned_msg</span><span class="o">.</span><span class="n">particles</span>
        <span class="n">new_log_density</span> <span class="o">=</span> <span class="n">cloned_msg</span><span class="o">.</span><span class="n">log_density</span>

        <span class="k">if</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Parameter</span> <span class="ow">in</span> <span class="n">cloned_msg</span><span class="o">.</span><span class="n">type</span><span class="p">:</span>
            <span class="k">assert</span> <span class="s1">&#39;dist_class&#39;</span> <span class="ow">in</span> <span class="n">cloned_msg</span><span class="o">.</span><span class="n">attr</span><span class="p">,</span> \
                <span class="s2">&quot;Missing &#39;dist_class&#39; message attribute when transforming a message that contains parameters.&quot;</span>
            <span class="n">new_parameters</span> <span class="o">=</span> <span class="n">DistributionServer</span><span class="o">.</span><span class="n">transform_param</span><span class="p">(</span><span class="n">new_parameters</span><span class="p">,</span> <span class="n">cloned_msg</span><span class="o">.</span><span class="n">attr</span><span class="p">[</span><span class="s1">&#39;dist_class&#39;</span><span class="p">],</span> <span class="n">trans</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span> <span class="ow">in</span> <span class="n">cloned_msg</span><span class="o">.</span><span class="n">type</span><span class="p">:</span>
            <span class="n">new_particles</span> <span class="o">=</span> <span class="n">trans</span><span class="p">(</span><span class="n">new_particles</span><span class="p">)</span>
            <span class="n">new_log_density</span> <span class="o">+=</span> <span class="n">trans</span><span class="o">.</span><span class="n">log_abs_det_jacobian</span><span class="p">(</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">particles</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">)</span>

        <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                          <span class="n">cloned_msg</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="n">cloned_msg</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">cloned_msg</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">cloned_msg</span><span class="o">.</span><span class="n">e_shape</span><span class="p">,</span>
                          <span class="n">new_parameters</span><span class="p">,</span> <span class="n">new_particles</span><span class="p">,</span> <span class="n">cloned_msg</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">new_log_density</span><span class="p">,</span> <span class="o">**</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_msg</span></div>

<div class="viewcode-block" id="Message.event_translate_2pred"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message.event_translate_2pred">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">event_translate_2pred</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="n">translator</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Translate msg&#39;s particles from PyTorch format to Cognitive format, using the given translator.</span>

<span class="sd">            If there are multiple r.v., will return a tuple of translated messages, elements corresponding to each r.v.</span>
<span class="sd">                specified in the translator. In this case, the particle weights and log sampling densities will be</span>
<span class="sd">                copied for each split event particles to form new messages.</span>

<span class="sd">            :param msg:             a Message instance. The message to be translated.</span>
<span class="sd">            :param translator:      a KnowledgeTranslator instance.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="n">Message</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">translator</span><span class="p">,</span> <span class="n">KnowledgeTranslator</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span> <span class="ow">in</span> <span class="n">msg</span><span class="o">.</span><span class="n">type</span>

        <span class="n">result_particles</span> <span class="o">=</span> <span class="n">translator</span><span class="o">.</span><span class="n">event2pred_event</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">particles</span><span class="p">)</span>

        <span class="n">result_msgs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result_particles</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result_particles</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
            <span class="n">result_particles</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">result_particles</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">particles</span> <span class="ow">in</span> <span class="n">result_particles</span><span class="p">:</span>
            <span class="c1"># Shape check</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">particles</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">particles</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">particles</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">msg</span><span class="o">.</span><span class="n">s_shape</span>
            <span class="c1"># Clone message</span>
            <span class="n">cloned_msg</span> <span class="o">=</span> <span class="n">msg</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="n">new_msg</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
                              <span class="n">cloned_msg</span><span class="o">.</span><span class="n">p_shape</span><span class="p">,</span> <span class="n">cloned_msg</span><span class="o">.</span><span class="n">s_shape</span><span class="p">,</span> <span class="n">cloned_msg</span><span class="o">.</span><span class="n">b_shape</span><span class="p">,</span> <span class="n">particles</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                              <span class="n">cloned_msg</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">particles</span><span class="p">,</span> <span class="n">cloned_msg</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">cloned_msg</span><span class="o">.</span><span class="n">log_density</span><span class="p">,</span>
                              <span class="o">**</span><span class="n">cloned_msg</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
            <span class="n">result_msgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_msg</span><span class="p">)</span>

        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">result_msgs</span><span class="p">)</span></div>

<div class="viewcode-block" id="Message.event_translate_2torch"><a class="viewcode-back" href="../../references/graphical/message.html#pysigma.defs.Message.event_translate_2torch">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">event_translate_2torch</span><span class="p">(</span><span class="n">msgs</span><span class="p">,</span> <span class="n">translator</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Translate provided iterable of messages&#39; particles from Cognitive format to form a message with particles in</span>
<span class="sd">                PyTorch format, using the given translator.</span>

<span class="sd">            The message order in the given iterable should conform to the random variable order specified in the</span>
<span class="sd">                translator.</span>

<span class="sd">            Return a single message.</span>

<span class="sd">            :param msgs:        an iterable of Message instances. Order should be compatible with the order of random</span>
<span class="sd">                                    variables specified in the given translator.</span>
<span class="sd">            :param translator:  a KnowledgeTranslator instance.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">msgs</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="n">Message</span><span class="p">)</span> <span class="k">for</span> <span class="n">msg</span> <span class="ow">in</span> <span class="n">msgs</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">translator</span><span class="p">,</span> <span class="n">KnowledgeTranslator</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">MessageType</span><span class="o">.</span><span class="n">Particles</span> <span class="ow">in</span> <span class="n">msg</span><span class="o">.</span><span class="n">type</span> <span class="k">for</span> <span class="n">msg</span> <span class="ow">in</span> <span class="n">msgs</span><span class="p">)</span>

        <span class="n">result_particles</span> <span class="o">=</span> <span class="n">translator</span><span class="o">.</span><span class="n">event2torch_event</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">msgs</span><span class="p">))</span></div></div>






<span class="c1"># TODO: Enum class of all the inference method</span>
<span class="k">class</span> <span class="nc">InferenceMethod</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="n">BP</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">PARTICLE_BP</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">VMP</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">PARTICLE_VMP</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">EP</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">PARTICLE_EP</span> <span class="o">=</span> <span class="mi">5</span>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Jincheng Zhou, Yunzhe Wang, Volkan Ustun, Paul Rosenbloom

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>